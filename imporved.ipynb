{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import miceforest as mf\n",
    "from missforest import MissForest\n",
    "import optuna\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import MIDASpy as md\n",
    "\n",
    "### Data Preparation Function\n",
    "\n",
    "# def prep(df: pd.DataFrame):\n",
    "#     \"\"\"\n",
    "#     Preprocess the DataFrame by:\n",
    "#     - Dropping rows with missing values and resetting the index.\n",
    "#     - Converting object columns to categorical via LabelEncoder.\n",
    "#     - Converting other columns to float (and then to int if >50% of values are integer-like).\n",
    "#     - If any numeric column (not already marked as categorical) has only 2 unique values,\n",
    "#       it is considered categorical and encoded.\n",
    "\n",
    "#     Returns:\n",
    "#         categorical_cols (list): List of columns encoded as categorical.\n",
    "#         discrete_cols (list): List of columns that are numeric and integer-like.\n",
    "#         cont_cols (list): List of remaining continuous numeric columns.\n",
    "#         df_clean (DataFrame): The preprocessed DataFrame.\n",
    "#         encoders (dict): Mapping from categorical column name to its LabelEncoder.\n",
    "#     \"\"\"\n",
    "#     df_clean = df.dropna().reset_index(drop=True)\n",
    "#     categorical_cols = []\n",
    "#     discrete_cols = []\n",
    "#     encoders = {}\n",
    "\n",
    "#     for col in df_clean.columns:\n",
    "#         if df_clean[col].dtype == 'object':\n",
    "#             categorical_cols.append(col)\n",
    "#             le = LabelEncoder()\n",
    "#             df_clean[col] = le.fit_transform(df_clean[col])\n",
    "#             encoders[col] = le\n",
    "#         else:\n",
    "#             try:\n",
    "#                 df_clean[col] = df_clean[col].astype(float)\n",
    "#                 if (np.isclose(df_clean[col] % 1, 0).mean() > 0.5):\n",
    "#                     df_clean[col] = df_clean[col].astype(int)\n",
    "#                     discrete_cols.append(col)\n",
    "#             except (ValueError, TypeError):\n",
    "#                 categorical_cols.append(col)\n",
    "#                 le = LabelEncoder()\n",
    "#                 df_clean[col] = le.fit_transform(df_clean[col])\n",
    "#                 encoders[col] = le\n",
    "\n",
    "#     for col in df_clean.columns:\n",
    "#         if col not in categorical_cols and df_clean[col].nunique() == 2:\n",
    "#             categorical_cols.append(col)\n",
    "#             le = LabelEncoder()\n",
    "#             df_clean[col] = le.fit_transform(df_clean[col])\n",
    "#             encoders[col] = le\n",
    "\n",
    "#     continuous_cols = [col for col in df_clean.columns if col not in categorical_cols + discrete_cols]\n",
    "\n",
    "#     return continuous_cols, discrete_cols, categorical_cols, df_clean, encoders\n",
    "def prep(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Preprocess the DataFrame by:\n",
    "    - Dropping rows with missing values and resetting the index.\n",
    "    - Converting object columns to categorical via LabelEncoder.\n",
    "    - Converting other columns to float (and then to int if >50% of values are integer-like).\n",
    "    - If any numeric column (not already marked as categorical) has only 2 unique values,\n",
    "      it is considered categorical and encoded.\n",
    "\n",
    "    Returns:\n",
    "        continuous_cols (list): List of remaining continuous numeric columns.\n",
    "        discrete_cols (list): List of columns that are numeric and integer-like.\n",
    "        categorical_cols (list): List of columns encoded as categorical.\n",
    "        df_clean (DataFrame): The preprocessed DataFrame.\n",
    "        encoders (dict): Mapping from categorical column name to its LabelEncoder.\n",
    "    \"\"\"\n",
    "    # Drop rows with missing values.\n",
    "    df_clean = df.dropna().reset_index(drop=True)\n",
    "    categorical_cols = []\n",
    "    discrete_cols = []\n",
    "    encoders = {}\n",
    "\n",
    "    # Loop over each column to check its type and convert accordingly.\n",
    "    for col in df_clean.columns:\n",
    "        # If the column type is object, encode it as a categorical variable.\n",
    "        if df_clean[col].dtype == 'object' or df_clean[col].nunique() == 2:\n",
    "            categorical_cols.append(col)\n",
    "            le = LabelEncoder()\n",
    "            df_clean[col] = le.fit_transform(df_clean[col])\n",
    "            encoders[col] = le\n",
    "        else:\n",
    "            try:\n",
    "                # Convert column to float first.\n",
    "                df_clean[col] = df_clean[col].astype(float)\n",
    "                # Check if most of the values are integer-like using np.isclose.\n",
    "                # This computes the proportion of values where the modulus with 1 is nearly 0.\n",
    "                if (np.isclose(df_clean[col] % 1, 0)).mean() > 0.5:\n",
    "                    df_clean[col] = df_clean[col].astype(int)\n",
    "                    discrete_cols.append(col)\n",
    "            except (ValueError, TypeError):\n",
    "                # If conversion to float fails, treat the column as categorical.\n",
    "                categorical_cols.append(col)\n",
    "                le = LabelEncoder()\n",
    "                df_clean[col] = le.fit_transform(df_clean[col])\n",
    "                encoders[col] = le\n",
    "\n",
    "    # # After the loop, check for numeric columns that have only two unique values.\n",
    "    # # If found, treat them as categorical.\n",
    "    # for col in df_clean.columns:\n",
    "    #     if col not in categorical_cols and df_clean[col].nunique() == 2:\n",
    "    #         categorical_cols.append(col)\n",
    "    #         le = LabelEncoder()\n",
    "    #         df_clean[col] = le.fit_transform(df_clean[col])\n",
    "    #         encoders[col] = le\n",
    "\n",
    "    # Determine continuous columns as those not flagged as categorical or discrete.\n",
    "    continuous_cols = [col for col in df_clean.columns if col not in categorical_cols + discrete_cols]\n",
    "\n",
    "    return continuous_cols, discrete_cols, categorical_cols, df_clean, encoders\n",
    "\n",
    "def reverse_encoding(df: pd.DataFrame, encoders: dict):\n",
    "    \"\"\"\n",
    "    Reverse the LabelEncoder transformation on categorical columns.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with encoded categorical columns.\n",
    "        encoders (dict): Dictionary mapping column names to their LabelEncoder.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with the categorical columns decoded to their original labels.\n",
    "    \"\"\"\n",
    "    df_decoded = df.copy()\n",
    "    for col, le in encoders.items():\n",
    "        df_decoded[col] = le.inverse_transform(df_decoded[col].astype(int))\n",
    "    return df_decoded\n",
    "\n",
    "def create_missings(df: pd.DataFrame, missingness: float, random_seed: float = 96):\n",
    "    \"\"\"\n",
    "    Create random missingness in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        missingness (float): Percentage of missing values to introduce.\n",
    "        random_seed (float): Seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Original DataFrame, DataFrame with missing values, and a mask DataFrame.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    mask = np.random.rand(*df.shape) < (missingness / 100)\n",
    "    mask_df = pd.DataFrame(mask, columns=df.columns)\n",
    "    df_missing = df.mask(mask)\n",
    "    return df, df_missing, mask_df\n",
    "\n",
    "def simulate_missingness(df, show_missingness=False):\n",
    "    \"\"\"\n",
    "    Simulate missingness by dropping rows with missing values and reintroducing them.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        show_missingness (bool): If True, prints missingness percentages.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Original DataFrame without missing values, simulated DataFrame with missingness, and a mask.\n",
    "    \"\"\"\n",
    "    missing_original = df.isna().mean()\n",
    "    df2 = df.dropna().reset_index(drop=True)\n",
    "    df3 = df2.copy()\n",
    "    missing_mask = pd.DataFrame(False, index=df3.index, columns=df3.columns)\n",
    "\n",
    "    for col in df3.columns:\n",
    "        n_missing = int(round(missing_original[col] * len(df3)))\n",
    "        if n_missing > 0:\n",
    "            missing_indices = df3.sample(n=n_missing, random_state=42).index\n",
    "            df3.loc[missing_indices, col] = np.nan\n",
    "            missing_mask.loc[missing_indices, col] = True\n",
    "\n",
    "    if show_missingness:\n",
    "        missing_df3 = df3.isna().mean()\n",
    "        print(\"Missingness Comparison:\")\n",
    "        for col in df.columns:\n",
    "            print(f\"Column '{col}': Original: {missing_original[col]*100:.2f}% \\t -> \\t df3: {missing_df3[col]*100:.2f}%\")\n",
    "\n",
    "    return df2, df3, missing_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"F:\\Work stuff\\Opthalmology\\berlin\\raw.xlsx\", 'raw')\n",
    "df = df.drop(columns=['نامونامخانوادگی'],axis=1)\n",
    "continuous_cols, discrete_cols, categorical_cols, df, encoders = prep(df)\n",
    "df, df2, missing_mask = create_missings(df, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_knn(df, continuous_cols=None, discrete_cols=None, categorical_cols=None, n_neighbors=5, scale=False):\n",
    "    \"\"\"\n",
    "    Impute missing values using KNN imputation over all columns.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with missing values.\n",
    "        continuous_cols (list): Names of continuous numeric columns.\n",
    "        discrete_cols (list): Names of discrete numeric columns.\n",
    "        categorical_cols (list): Names of categorical columns.\n",
    "        n_neighbors (int): Number of neighbors for KNN.\n",
    "        scale (bool): Whether to apply MinMaxScaler before imputation.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Imputed DataFrame.\n",
    "    \"\"\"\n",
    "    df_imputed = df.copy()\n",
    "\n",
    "    # Optionally scale all numeric columns\n",
    "    if scale:\n",
    "        scaler = MinMaxScaler()\n",
    "        df_imputed[df.columns] = scaler.fit_transform(df_imputed)\n",
    "\n",
    "    # Apply KNN imputation to the entire dataframe\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "    df_imputed[df.columns] = imputer.fit_transform(df_imputed)\n",
    "\n",
    "    # Reverse scale if needed\n",
    "    if scale:\n",
    "        df_imputed[df.columns] = scaler.inverse_transform(df_imputed)\n",
    "\n",
    "    # Post-process: round discrete and categorical values\n",
    "    if discrete_cols:\n",
    "        df_imputed[discrete_cols] = np.round(df_imputed[discrete_cols]).astype(int)\n",
    "    if categorical_cols:\n",
    "        df_imputed[categorical_cols] = np.round(df_imputed[categorical_cols]).astype(int)\n",
    "\n",
    "    return df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_imputed = do_knn(df2, continuous_cols=None, discrete_cols=None, categorical_cols=None, n_neighbors=5, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_mice(df, continuous_cols=None, discrete_cols=None, categorical_cols=None,\n",
    "            iters=10, strat='normal', scale=False):\n",
    "    \"\"\"\n",
    "    Impute missing values in a DataFrame using the MICE forest method.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with missing values.\n",
    "        continuous_cols (list of str): Names of continuous numeric columns.\n",
    "        discrete_cols (list of str): Names of discrete numeric columns.\n",
    "        categorical_cols (list of str): Names of categorical columns.\n",
    "        iters (int): Number of MICE iterations.\n",
    "        strat: ['normal', 'shap', 'fast'] or a dictionary specifying the mean matching strategy.\n",
    "        scale (bool): Whether to apply MinMaxScaler before imputation.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Imputed DataFrame.\n",
    "    \"\"\"\n",
    "    df_imputed = df.copy()\n",
    "\n",
    "    if scale:\n",
    "        scaler = MinMaxScaler()\n",
    "        df_imputed[continuous_cols] = scaler.fit_transform(df_imputed[continuous_cols])\n",
    "\n",
    "    kernel = mf.ImputationKernel(\n",
    "        df_imputed,\n",
    "        random_state=0,\n",
    "        mean_match_strategy=strat,\n",
    "        variable_schema=None,  # Explicitly set variable_schema to None \n",
    "        )\n",
    "\n",
    "    kernel.mice(iterations=iters, verbose=False)  # Disable verbose output\n",
    "    df_completed = kernel.complete_data(dataset=0)\n",
    "\n",
    "    if discrete_cols:\n",
    "        df_completed[discrete_cols] = df_completed[discrete_cols].round().astype(int)\n",
    "    if categorical_cols:\n",
    "        df_completed[categorical_cols] = df_completed[categorical_cols].round().astype(int)\n",
    "\n",
    "    if scale:\n",
    "        scaler = MinMaxScaler()\n",
    "        df_completed[continuous_cols] = scaler.inverse_transform(df_completed[continuous_cols])\n",
    "\n",
    "    return df_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mice_imputed = do_mice(df2, continuous_cols=continuous_cols, discrete_cols=discrete_cols, categorical_cols=categorical_cols,\n",
    "                    #    iters=10, strat='normal', scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def do_mf(df, continuous_cols=None, discrete_cols=None, categorical_cols=None, iters=5, scale=False):\n",
    "    \"\"\"\n",
    "    Impute missing values using MissForest.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with missing values.\n",
    "        continuous_cols (list): Names of continuous numeric columns.\n",
    "        discrete_cols (list): Names of discrete numeric columns.\n",
    "        categorical_cols (list): Names of categorical columns.\n",
    "        iters (int): Maximum number of iterations.\n",
    "        scale (bool): Whether to apply MinMaxScaler before imputation.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Imputed DataFrame.\n",
    "    \"\"\"\n",
    "    df_imputed = df.copy()\n",
    "    \n",
    "    if scale:\n",
    "        scaler = MinMaxScaler()\n",
    "        df_imputed[continuous_cols] = scaler.fit_transform(df_imputed[continuous_cols])\n",
    "    \n",
    "    imputer = MissForest(max_iter=iters, categorical=categorical_cols)\n",
    "    df_imputed_result = imputer.fit_transform(df_imputed)\n",
    "    \n",
    "    if discrete_cols:\n",
    "        df_imputed_result[discrete_cols] = df_imputed_result[discrete_cols].round().astype(int)\n",
    "    \n",
    "    if categorical_cols:\n",
    "        df_imputed_result[categorical_cols] = df_imputed_result[categorical_cols].round().astype(int)\n",
    "    \n",
    "    if scale:\n",
    "        # Reverse scaling for continuous columns\n",
    "        df_imputed_result[continuous_cols] = scaler.inverse_transform(df_imputed_result[continuous_cols])\n",
    "    \n",
    "    return df_imputed_result\n",
    "\n",
    "# mf_imputed = do_mf(df2, continuous_cols=continuous_cols, discrete_cols=discrete_cols, categorical_cols=categorical_cols, iters=5, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_midas(df, continuous_cols=None, discrete_cols=None, categorical_cols=None,\n",
    "              layer:list=[256,256], vae:bool=True, samples:int=10, random_seed:float=96 ):\n",
    "    \"\"\"\n",
    "    Imputes missing values using the MIDAS model.\n",
    "    \n",
    "    Parameters:\n",
    "      df (pd.DataFrame): Input dataframe.\n",
    "      continuous_cols (list): List of continuous column names.\n",
    "      discrete_cols (list): List of discrete (numeric but non-continuous) column names.\n",
    "      categorical_cols (list): List of categorical column names.\n",
    "      \n",
    "    Returns:\n",
    "      imps (list): A list of imputed dataframes.\n",
    "    \"\"\"\n",
    "    # 1. Convert categorical columns and get categorical metadata.\n",
    "    md_cat_data, md_cats = md.cat_conv(df[categorical_cols])\n",
    "    \n",
    "    # 2. Define the numeric columns.\n",
    "    num_cols = discrete_cols + continuous_cols  # these are the numeric columns\n",
    "\n",
    "    # 3. Drop original categorical columns and combine with the converted categorical data.\n",
    "    df_copy = df.drop(columns=categorical_cols,axis=1)\n",
    "    constructor_list = [df_copy, md_cat_data]\n",
    "    data_in = pd.concat(constructor_list, axis=1)\n",
    "    \n",
    "    # 4. Scale non-categorical columns BEFORE imputation.\n",
    "    scaler = MinMaxScaler()\n",
    "    data_in[num_cols] = scaler.fit_transform(data_in[num_cols])\n",
    "    \n",
    "    # 5. Build and train the imputer using the scaled data.\n",
    "    imputer = md.Midas(layer_structure=layer, vae_layer=vae, seed=random_seed, input_drop=0.75)\n",
    "    # Use md_cats as softmax columns for categorical outputs.\n",
    "    imputer.build_model(data_in, softmax_columns=md_cats)\n",
    "    imputer.train_model(training_epochs=20)\n",
    "    \n",
    "    # 6. Generate imputations.\n",
    "    imps = imputer.generate_samples(m=samples).output_list\n",
    "    \n",
    "    # 7. Post-process each imputed DataFrame.\n",
    "    for idx, imp_df in enumerate(imps):\n",
    "        # Reverse transform the numeric columns.\n",
    "        imp_df[num_cols] = scaler.inverse_transform(imp_df[num_cols])\n",
    "        \n",
    "        # Process categorical columns.\n",
    "        # For each softmax group in md_cats, choose the column with the highest probability.\n",
    "        tmp_cat = []\n",
    "        for group in md_cats:\n",
    "            # idxmax returns the column name with maximum value per row for this group.\n",
    "            tmp_cat.append(imp_df[group].idxmax(axis=1))\n",
    "        # Assume the order of md_cats corresponds to categorical_cols.\n",
    "        cat_df = pd.DataFrame({categorical_cols[j]: tmp_cat[j] for j in range(len(categorical_cols))})\n",
    "        \n",
    "        # Drop the softmax columns.\n",
    "        flat_cats = [col for group in md_cats for col in group]\n",
    "        tmp_cat = [imp_df[x].idxmax(axis=1) for x in md_cats]\n",
    "        cat_df = pd.DataFrame({categorical_cols[j]: tmp_cat[j] for j in range(len(categorical_cols))})\n",
    "        imp_df = pd.concat([imp_df, cat_df], axis=1).drop(columns=flat_cats, axis=1)\n",
    "        \n",
    "        # Handle discrete data by rounding the values.\n",
    "        imp_df[discrete_cols] = imp_df[discrete_cols].round()\n",
    "        \n",
    "        # Replace the processed DataFrame in the list.\n",
    "        imps[idx] = imp_df\n",
    "\n",
    "        ### make method info\n",
    "        method_info = f'MIDAS, params: samples={samples} ,layer={layer}, vae={vae}'\n",
    "    return imps, method_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midas_imputed = do_midas(df2, continuous_cols=continuous_cols, discrete_cols=discrete_cols, categorical_cols=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Missingness Creation Function\n",
    "# ------------------------------------------------------------------------------\n",
    "def create_missings(df: pd.DataFrame, missingness: float, random_seed: float = 96):\n",
    "    \"\"\"\n",
    "    Create random missingness in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        missingness (float): Percentage of missing values to introduce.\n",
    "        random_seed (float): Seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (original DataFrame, DataFrame with missing values, mask DataFrame)\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    mask = np.random.rand(*df.shape) < (missingness / 100)\n",
    "    mask_df = pd.DataFrame(mask, columns=df.columns)\n",
    "    df_missing = df.mask(mask)\n",
    "    return df, df_missing, mask_df\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Improved Evaluation Function\n",
    "# ------------------------------------------------------------------------------\n",
    "def select_best_imputations(imputed_dfs, original_df, mask_df, continuous_cols, discrete_cols, categorical_cols, method_info=None, method_names=None):\n",
    "    \"\"\"\n",
    "    Evaluate one or several imputed DataFrames and determine an aggregated error.\n",
    "\n",
    "    For each column with simulated missing data (per mask_df), numeric columns\n",
    "    are scored using Mean Absolute Error (MAE) while categorical columns are scored\n",
    "    by misclassification rate (1 - accuracy). An overall aggregated error is returned,\n",
    "    which is the mean error over all evaluated columns.\n",
    "\n",
    "    Parameters:\n",
    "      imputed_dfs (list of pd.DataFrame): A list of imputed DataFrames.\n",
    "      original_df (pd.DataFrame): The original (complete) DataFrame.\n",
    "      mask_df (pd.DataFrame): Boolean DataFrame with True at positions where values are masked.\n",
    "      continuous_cols (list): List of continuous numeric column names.\n",
    "      discrete_cols (list): List of discrete numeric column names.\n",
    "      categorical_cols (list): List of categorical column names.\n",
    "      method_info (str, optional): Text description of the method and its hyperparameters.\n",
    "      method_names (list, optional): List of names for each imputation method candidate.\n",
    "\n",
    "    Returns:\n",
    "      best_imputed_df (pd.DataFrame): A DataFrame where, for each column with missing values,\n",
    "                                     the candidate with the lowest error is chosen.\n",
    "      summary_table (pd.DataFrame): A summary table with metrics for each column.\n",
    "      aggregated_error (float): The average error across columns (lower is better).\n",
    "    \"\"\"\n",
    "    n_methods = len(imputed_dfs)\n",
    "    \n",
    "    if method_info is not None:\n",
    "        parts = method_info.split(',')\n",
    "        base_name = parts[0].strip()\n",
    "        params = ','.join(parts[1:]).strip() if len(parts) > 1 else \"\"\n",
    "        method_names = [f\"{base_name} ({params})\"] * n_methods\n",
    "    elif method_names is None:\n",
    "        method_names = [f\"Method {i+1}\" for i in range(n_methods)]\n",
    "    \n",
    "    summary_list = []\n",
    "    best_method_per_col = {}\n",
    "\n",
    "    for col in original_df.columns:\n",
    "        if col in continuous_cols:\n",
    "            col_type = \"Continuous\"\n",
    "        elif col in discrete_cols:\n",
    "            col_type = \"Discrete\"\n",
    "        elif col in categorical_cols:\n",
    "            col_type = \"Categorical\"\n",
    "        else:\n",
    "            col_type = str(original_df[col].dtype)\n",
    "\n",
    "        if mask_df[col].sum() == 0:\n",
    "            best_method_per_col[col] = None\n",
    "            summary_list.append({\n",
    "                'Column': col,\n",
    "                'Data Type': col_type,\n",
    "                'Best Method': None,\n",
    "                'Metric': np.nan,  \n",
    "            })\n",
    "            continue\n",
    "\n",
    "        col_errors = []\n",
    "        for df_imp in imputed_dfs:\n",
    "            if col_type in [\"Continuous\", \"Discrete\"]:\n",
    "                try:\n",
    "                    imp_vals = pd.to_numeric(df_imp[col][mask_df[col]], errors='coerce')\n",
    "                    orig_vals = pd.to_numeric(original_df[col][mask_df[col]], errors='coerce')\n",
    "                except Exception as e:\n",
    "                    imp_vals = df_imp[col][mask_df[col]]\n",
    "                    orig_vals = original_df[col][mask_df[col]]\n",
    "                errors = np.abs(imp_vals - orig_vals)\n",
    "                mae = errors.mean()\n",
    "                col_errors.append(mae)\n",
    "            else:\n",
    "                correct = (df_imp[col][mask_df[col]] == original_df[col][mask_df[col]])\n",
    "                accuracy = correct.mean()\n",
    "                col_errors.append(1 - accuracy)\n",
    "\n",
    "        if col_type in [\"Continuous\", \"Discrete\"]:\n",
    "            best_idx = int(np.nanargmin(col_errors))\n",
    "        else:\n",
    "            best_idx = int(np.nanargmin(col_errors))\n",
    "        best_method = method_names[best_idx]\n",
    "        best_metric = col_errors[best_idx]\n",
    "\n",
    "        best_method_per_col[col] = best_idx\n",
    "        summary_list.append({\n",
    "            'Column': col,\n",
    "            'Data Type': col_type,\n",
    "            'Best Method': best_method,\n",
    "            'Metric': best_metric,\n",
    "        })\n",
    "\n",
    "    summary_table = pd.DataFrame(summary_list)\n",
    "    \n",
    "    best_imputed_df = original_df.copy()\n",
    "    for col in original_df.columns:\n",
    "        if mask_df[col].sum() > 0 and best_method_per_col[col] is not None:\n",
    "            method_idx = best_method_per_col[col]\n",
    "            best_imputed_df.loc[mask_df[col], col] = imputed_dfs[method_idx].loc[mask_df[col], col]\n",
    "\n",
    "    errors = summary_table['Metric'].dropna().values\n",
    "    aggregated_error = np.mean(errors) if len(errors) > 0 else np.nan\n",
    "\n",
    "    return best_imputed_df, summary_table, aggregated_error\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Hyperparameter Optimization Function using Optuna\n",
    "# ------------------------------------------------------------------------------\n",
    "def optimize_imputation_hyperparams(imputation_func, \n",
    "                                    original_df, \n",
    "                                    missing_percent, \n",
    "                                    continuous_cols, \n",
    "                                    discrete_cols, \n",
    "                                    categorical_cols, \n",
    "                                    timelimit=600,    # in seconds\n",
    "                                    min_trials=20,\n",
    "                                    random_seed=96):\n",
    "    \"\"\"\n",
    "    Optimize hyperparameters for an imputation function using Optuna.\n",
    "\n",
    "    This function takes the complete (original) DataFrame and a missing percentage.\n",
    "    It uses `create_missings` to generate a DataFrame with simulated missing values and\n",
    "    a corresponding mask. Then it runs the candidate imputation method on the incomplete\n",
    "    DataFrame, evaluates the imputed results against the original DataFrame using the mask,\n",
    "    and guides the hyperparameter search based on an aggregated error (lower is better).\n",
    "\n",
    "    Parameters:\n",
    "        imputation_func (callable): An imputation function (do_knn, do_mice, do_mf, or do_midas).\n",
    "        original_df (pd.DataFrame): The complete ground-truth DataFrame.\n",
    "        missing_percent (float): Percentage of missing values to simulate.\n",
    "        continuous_cols (list): List of continuous numeric column names.\n",
    "        discrete_cols (list): List of discrete numeric column names.\n",
    "        categorical_cols (list): List of categorical column names.\n",
    "        timelimit (int): Maximum time in seconds to run the optimization.\n",
    "        min_trials (int): Minimum number of Optuna trials to run.\n",
    "        random_seed (int): Seed for generating missingness (passed to create_missings).\n",
    "\n",
    "    Returns:\n",
    "        best_trial: The best trial object from the study.\n",
    "        best_value: The best (lowest) aggregated objective value.\n",
    "    \"\"\"\n",
    "    # Generate missing values and mask using the provided function.\n",
    "    _, df_missing, mask_df = create_missings(original_df, missingness=missing_percent, random_seed=random_seed)\n",
    "\n",
    "    def objective(trial):\n",
    "        func_name = imputation_func.__name__\n",
    "        params = {}\n",
    "\n",
    "        if func_name == \"do_knn\":\n",
    "            params['n_neighbors'] = trial.suggest_int(\"n_neighbors\", 3, 15)\n",
    "            params['scale'] = trial.suggest_categorical(\"scale\", [True, False])\n",
    "            # Run imputation on df_missing, not the original complete data.\n",
    "            imputed_df = imputation_func(df_missing, \n",
    "                                         continuous_cols=continuous_cols, \n",
    "                                         discrete_cols=discrete_cols, \n",
    "                                         categorical_cols=categorical_cols, \n",
    "                                         **params)\n",
    "            imputed_dfs = [imputed_df]\n",
    "            method_info = f\"KNN, n_neighbors={params['n_neighbors']}, scale={params['scale']}\"\n",
    "        elif func_name == \"do_mice\":\n",
    "            params['iters'] = trial.suggest_int(\"iters\", 5, 20)\n",
    "            params['strat'] = trial.suggest_categorical(\"strat\", ['normal', 'shap', 'fast'])\n",
    "            params['scale'] = trial.suggest_categorical(\"scale\", [True, False])\n",
    "            imputed_df = imputation_func(df_missing,\n",
    "                                         continuous_cols=continuous_cols, \n",
    "                                         discrete_cols=discrete_cols, \n",
    "                                         categorical_cols=categorical_cols,\n",
    "                                         **params)\n",
    "            imputed_dfs = [imputed_df]\n",
    "            method_info = f\"MICE, iters={params['iters']}, strat={params['strat']}, scale={params['scale']}\"\n",
    "        elif func_name == \"do_mf\":\n",
    "            params['iters'] = trial.suggest_int(\"iters\", 3, 15)\n",
    "            params['scale'] = trial.suggest_categorical(\"scale\", [True, False])\n",
    "            imputed_df = imputation_func(df_missing,\n",
    "                                         continuous_cols=continuous_cols, \n",
    "                                         discrete_cols=discrete_cols, \n",
    "                                         categorical_cols=categorical_cols,\n",
    "                                         **params)\n",
    "            imputed_dfs = [imputed_df]\n",
    "            method_info = f\"MissForest, iters={params['iters']}, scale={params['scale']}\"\n",
    "        elif func_name == \"do_midas\":\n",
    "            params['layer'] = trial.suggest_categorical(\"layer\", [[256,256], [128,128], [512,256]])\n",
    "            params['vae'] = trial.suggest_categorical(\"vae\", [True, False])\n",
    "            params['samples'] = trial.suggest_int(\"samples\", 5, 20)\n",
    "            imputed_dfs, method_info = imputation_func(df_missing,\n",
    "                                                       continuous_cols=continuous_cols, \n",
    "                                                       discrete_cols=discrete_cols, \n",
    "                                                       categorical_cols=categorical_cols,\n",
    "                                                       **params)\n",
    "            imputed_dfs = [imputed_dfs[0]]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported imputation function: {func_name}\")\n",
    "\n",
    "        # Evaluate the imputed result by comparing against the original complete DataFrame.\n",
    "        _, summary_table, aggregated_error = select_best_imputations(\n",
    "            imputed_dfs, original_df, mask_df, continuous_cols, discrete_cols, categorical_cols,\n",
    "            method_info=method_info\n",
    "        )\n",
    "\n",
    "        if np.isnan(aggregated_error):\n",
    "            aggregated_error = 1e6\n",
    "\n",
    "        return aggregated_error\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, timeout=timelimit, n_trials=min_trials)\n",
    "\n",
    "    best_trial = study.best_trial\n",
    "    best_value = best_trial.value\n",
    "\n",
    "    print(\"Optimization completed!\")\n",
    "    print(\"Best Trial Hyperparameters:\")\n",
    "    for key, value in best_trial.params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(f\"Best Objective Value (aggregated error): {best_value}\")\n",
    "\n",
    "    return best_trial, best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 11:25:51,470] A new study created in memory with name: no-name-5daafcc4-498d-4e71-9799-8a077f4c244d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 11:25:52,005] Trial 0 finished with value: 12.147824823621622 and parameters: {'n_neighbors': 10, 'scale': True}. Best is trial 0 with value: 12.147824823621622.\n",
      "[I 2025-04-14 11:25:52,494] Trial 1 finished with value: 12.844363889321443 and parameters: {'n_neighbors': 15, 'scale': True}. Best is trial 0 with value: 12.147824823621622.\n",
      "[I 2025-04-14 11:25:52,996] Trial 2 finished with value: 11.079757802848631 and parameters: {'n_neighbors': 6, 'scale': True}. Best is trial 2 with value: 11.079757802848631.\n",
      "[I 2025-04-14 11:25:53,372] Trial 3 finished with value: 10.64311847733934 and parameters: {'n_neighbors': 3, 'scale': False}. Best is trial 3 with value: 10.64311847733934.\n",
      "[I 2025-04-14 11:25:53,797] Trial 4 finished with value: 11.096930132690385 and parameters: {'n_neighbors': 6, 'scale': False}. Best is trial 3 with value: 10.64311847733934.\n",
      "[I 2025-04-14 11:25:54,202] Trial 5 finished with value: 11.096930132690385 and parameters: {'n_neighbors': 6, 'scale': False}. Best is trial 3 with value: 10.64311847733934.\n",
      "[I 2025-04-14 11:25:54,605] Trial 6 finished with value: 10.47046431270568 and parameters: {'n_neighbors': 4, 'scale': False}. Best is trial 6 with value: 10.47046431270568.\n",
      "[I 2025-04-14 11:25:55,009] Trial 7 finished with value: 12.031134537713058 and parameters: {'n_neighbors': 7, 'scale': False}. Best is trial 6 with value: 10.47046431270568.\n",
      "[I 2025-04-14 11:25:55,513] Trial 8 finished with value: 12.430937947477517 and parameters: {'n_neighbors': 12, 'scale': True}. Best is trial 6 with value: 10.47046431270568.\n",
      "[I 2025-04-14 11:25:55,927] Trial 9 finished with value: 12.701654305516625 and parameters: {'n_neighbors': 12, 'scale': False}. Best is trial 6 with value: 10.47046431270568.\n",
      "[I 2025-04-14 11:25:56,350] Trial 10 finished with value: 10.64311847733934 and parameters: {'n_neighbors': 3, 'scale': False}. Best is trial 6 with value: 10.47046431270568.\n",
      "[I 2025-04-14 11:25:56,820] Trial 11 finished with value: 10.64311847733934 and parameters: {'n_neighbors': 3, 'scale': False}. Best is trial 6 with value: 10.47046431270568.\n",
      "[I 2025-04-14 11:25:57,288] Trial 12 finished with value: 10.64311847733934 and parameters: {'n_neighbors': 3, 'scale': False}. Best is trial 6 with value: 10.47046431270568.\n",
      "[I 2025-04-14 11:25:57,737] Trial 13 finished with value: 10.740198616483436 and parameters: {'n_neighbors': 5, 'scale': False}. Best is trial 6 with value: 10.47046431270568.\n",
      "[I 2025-04-14 11:25:58,153] Trial 14 finished with value: 11.82626068729432 and parameters: {'n_neighbors': 8, 'scale': False}. Best is trial 6 with value: 10.47046431270568.\n",
      "[I 2025-04-14 11:25:58,586] Trial 15 finished with value: 10.47046431270568 and parameters: {'n_neighbors': 4, 'scale': False}. Best is trial 6 with value: 10.47046431270568.\n",
      "[I 2025-04-14 11:25:59,012] Trial 16 finished with value: 12.159053002215831 and parameters: {'n_neighbors': 9, 'scale': False}. Best is trial 6 with value: 10.47046431270568.\n",
      "[I 2025-04-14 11:25:59,474] Trial 17 finished with value: 10.740198616483436 and parameters: {'n_neighbors': 5, 'scale': False}. Best is trial 6 with value: 10.47046431270568.\n",
      "[I 2025-04-14 11:25:59,946] Trial 18 finished with value: 11.213113540959439 and parameters: {'n_neighbors': 5, 'scale': True}. Best is trial 6 with value: 10.47046431270568.\n",
      "[I 2025-04-14 11:26:00,401] Trial 19 finished with value: 12.49971246398395 and parameters: {'n_neighbors': 11, 'scale': False}. Best is trial 6 with value: 10.47046431270568.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization completed!\n",
      "Best Trial Hyperparameters:\n",
      "  n_neighbors: 4\n",
      "  scale: False\n",
      "Best Objective Value (aggregated error): 10.47046431270568\n"
     ]
    }
   ],
   "source": [
    "best_method, best_val = optimize_imputation_hyperparams(imputation_func=do_knn,original_df=df,missing_percent=20,\n",
    "                                                        continuous_cols=continuous_cols, discrete_cols=discrete_cols, categorical_cols=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_method, best_val = optimize_imputation_hyperparams(imputation_func=do_mf,original_df=df,missing_percent=20,\n",
    "                                                        continuous_cols=continuous_cols, discrete_cols=discrete_cols, categorical_cols=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_method, best_val = optimize_imputation_hyperparams(imputation_func=do_midas,original_df=df,missing_percent=20,timelimit=300,\n",
    "                                                        continuous_cols=continuous_cols, discrete_cols=discrete_cols, categorical_cols=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_method, best_val = optimize_imputation_hyperparams(imputation_func=do_mice,original_df=df,missing_percent=20,timelimit=300,\n",
    "                                                        continuous_cols=continuous_cols, discrete_cols=discrete_cols, categorical_cols=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_excel(r\"C:\\Users\\Matin\\Downloads\\Data for Dr.Matin.xlsx\", 's1')\n",
    "new_df.drop(['n', 'ID','Gen.code'],axis=1,inplace=True)\n",
    "continuous_cols, discrete_cols, categorical_cols, df2, encoders = prep(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dm4',\n",
       " 'E11',\n",
       " 'E12',\n",
       " 'E21',\n",
       " 'E22',\n",
       " 'E31',\n",
       " 'E32',\n",
       " 'E41',\n",
       " 'E42',\n",
       " 'E24',\n",
       " 'E25',\n",
       " 'E26',\n",
       " 'E27',\n",
       " 'FastingBloodSugar',\n",
       " 'Glucose2hpp',\n",
       " 'Cholestrol',\n",
       " 'Triglycerides',\n",
       " 'HDL',\n",
       " 'LDL',\n",
       " 'W.B.C',\n",
       " 'Platelets',\n",
       " 'DBP',\n",
       " 'SBP',\n",
       " 'gdi',\n",
       " 'work_activity',\n",
       " 'transport',\n",
       " 'lesiretime']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-17 00:48:47,368] A new study created in memory with name: no-name-c7f21880-10ec-48f1-9a0c-390fa32a9351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-17 00:48:48,711] Trial 0 finished with value: 128853.83079579413 and parameters: {'n_neighbors': 8, 'scale': False}. Best is trial 0 with value: 128853.83079579413.\n",
      "[I 2025-04-17 00:48:50,077] Trial 1 finished with value: 127580.80474204637 and parameters: {'n_neighbors': 11, 'scale': False}. Best is trial 1 with value: 127580.80474204637.\n",
      "[I 2025-04-17 00:48:51,376] Trial 2 finished with value: 123864.30822936769 and parameters: {'n_neighbors': 4, 'scale': True}. Best is trial 2 with value: 123864.30822936769.\n",
      "[I 2025-04-17 00:48:52,691] Trial 3 finished with value: 122415.90668441085 and parameters: {'n_neighbors': 6, 'scale': True}. Best is trial 3 with value: 122415.90668441085.\n",
      "[I 2025-04-17 00:48:54,019] Trial 4 finished with value: 120331.31492166221 and parameters: {'n_neighbors': 9, 'scale': True}. Best is trial 4 with value: 120331.31492166221.\n",
      "[I 2025-04-17 00:48:55,349] Trial 5 finished with value: 126572.80990000315 and parameters: {'n_neighbors': 13, 'scale': False}. Best is trial 4 with value: 120331.31492166221.\n",
      "[I 2025-04-17 00:48:56,677] Trial 6 finished with value: 129706.18415046412 and parameters: {'n_neighbors': 4, 'scale': False}. Best is trial 4 with value: 120331.31492166221.\n",
      "[I 2025-04-17 00:48:57,988] Trial 7 finished with value: 128744.0016420219 and parameters: {'n_neighbors': 5, 'scale': False}. Best is trial 4 with value: 120331.31492166221.\n",
      "[I 2025-04-17 00:48:59,359] Trial 8 finished with value: 122003.54089005863 and parameters: {'n_neighbors': 7, 'scale': True}. Best is trial 4 with value: 120331.31492166221.\n",
      "[I 2025-04-17 00:49:00,699] Trial 9 finished with value: 129387.21065782357 and parameters: {'n_neighbors': 6, 'scale': False}. Best is trial 4 with value: 120331.31492166221.\n",
      "[I 2025-04-17 00:49:02,061] Trial 10 finished with value: 119973.72216037614 and parameters: {'n_neighbors': 15, 'scale': True}. Best is trial 10 with value: 119973.72216037614.\n",
      "[I 2025-04-17 00:49:03,401] Trial 11 finished with value: 119973.72216037614 and parameters: {'n_neighbors': 15, 'scale': True}. Best is trial 10 with value: 119973.72216037614.\n",
      "[I 2025-04-17 00:49:04,746] Trial 12 finished with value: 119973.72216037614 and parameters: {'n_neighbors': 15, 'scale': True}. Best is trial 10 with value: 119973.72216037614.\n",
      "[I 2025-04-17 00:49:06,078] Trial 13 finished with value: 119973.72216037614 and parameters: {'n_neighbors': 15, 'scale': True}. Best is trial 10 with value: 119973.72216037614.\n",
      "[I 2025-04-17 00:49:07,403] Trial 14 finished with value: 119049.68301431432 and parameters: {'n_neighbors': 12, 'scale': True}. Best is trial 14 with value: 119049.68301431432.\n",
      "[I 2025-04-17 00:49:08,732] Trial 15 finished with value: 119049.68301431432 and parameters: {'n_neighbors': 12, 'scale': True}. Best is trial 14 with value: 119049.68301431432.\n",
      "[I 2025-04-17 00:49:10,050] Trial 16 finished with value: 119215.35280781155 and parameters: {'n_neighbors': 11, 'scale': True}. Best is trial 14 with value: 119049.68301431432.\n",
      "[I 2025-04-17 00:49:11,380] Trial 17 finished with value: 119049.68301431432 and parameters: {'n_neighbors': 12, 'scale': True}. Best is trial 14 with value: 119049.68301431432.\n",
      "[I 2025-04-17 00:49:12,713] Trial 18 finished with value: 119520.9730044073 and parameters: {'n_neighbors': 13, 'scale': True}. Best is trial 14 with value: 119049.68301431432.\n",
      "[I 2025-04-17 00:49:14,026] Trial 19 finished with value: 119602.39668843981 and parameters: {'n_neighbors': 10, 'scale': True}. Best is trial 14 with value: 119049.68301431432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization completed!\n",
      "Best Trial Hyperparameters:\n",
      "  n_neighbors: 12\n",
      "  scale: True\n",
      "Best Objective Value (aggregated error): 119049.68301431432\n"
     ]
    }
   ],
   "source": [
    "best_method, best_val = optimize_imputation_hyperparams(imputation_func=do_knn,original_df=df2,missing_percent=30,\n",
    "                                                        continuous_cols=continuous_cols, discrete_cols=discrete_cols, categorical_cols=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Gen.code",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Dm2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Dm4",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "E11",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "E12",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "E21",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "E22",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "E31",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "E32",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "E41",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "E42",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "E23",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "E24",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "E25",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "E26",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "E27",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "FastingBloodSugar",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Glucose2hpp",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Cholestrol",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Triglycerides",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "HDL",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "LDL",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Hb.A1C",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CreatininUrine",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PotassiumUrineRandom",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SodiumUrineRandom",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "W.B.C",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "R.B.C",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Hemoglobin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Hematocrit",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MCV",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MCH",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MCHC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Neutrophils",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Lymphocyte",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Mixed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Platelets",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "DBP",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "SBP",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "gdi",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "work_activity",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "transport",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "lesiretime",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "574de882-11db-4bbf-8574-83d092f8165f",
       "rows": [
        [
         "0",
         "1",
         "1",
         "1090",
         "1",
         "36",
         "80",
         "75",
         "30",
         "20",
         "130",
         "110",
         "75",
         "60",
         "74.7",
         "169",
         "73",
         "106",
         "22",
         "84",
         "89",
         "211",
         "166",
         "38",
         "117",
         "5.5",
         "285.0",
         "55.6",
         "137.4",
         "7700",
         "5.56",
         "17.2",
         "46.8",
         "84.2",
         "30.9",
         "36.8",
         "35.8",
         "52.6",
         "11.6",
         "249",
         "67",
         "120",
         "6",
         "34560",
         "2391444",
         "1440"
        ],
        [
         "1",
         "2",
         "0",
         "743",
         "0",
         "59",
         "65",
         "62",
         "16",
         "16",
         "132",
         "125",
         "76",
         "76",
         "74.0",
         "163",
         "105",
         "114",
         "16",
         "83",
         "70",
         "225",
         "95",
         "62",
         "125",
         "4.1",
         "123.4",
         "34.8",
         "180.6",
         "3900",
         "4.56",
         "14.5",
         "40.9",
         "89.7",
         "31.8",
         "35.5",
         "52.5",
         "36.4",
         "11.1",
         "226",
         "76",
         "128",
         "5",
         "7174332",
         "360",
         "7174332"
        ],
        [
         "2",
         "3",
         "0",
         "242",
         "0",
         "58",
         "83",
         "85",
         "17",
         "17",
         "120",
         "120",
         "70",
         "70",
         "82.0",
         "160",
         "112",
         "116",
         "22",
         "116",
         "131",
         "167",
         "122",
         "49",
         "90",
         "5.3",
         "45.39",
         "31.44",
         "66.2",
         "6700",
         "5.18",
         "15.2",
         "43.6",
         "84.2",
         "29.3",
         "34.9",
         "58.8",
         "32.1",
         "9.1",
         "288",
         "70",
         "120",
         "5",
         "4783608",
         "480",
         "7174332"
        ],
        [
         "3",
         "4",
         "1",
         "33",
         "0",
         "61",
         "69",
         "70",
         "29",
         "29",
         "140",
         "130",
         "80",
         "60",
         "76.9",
         "156",
         "107",
         "109",
         "20",
         "106",
         "105",
         "236",
         "194",
         "38",
         "138",
         "6.22",
         "290.7",
         "113.8",
         "160.0",
         "4000",
         "4.65",
         "14.0",
         "39.5",
         "84.9",
         "30.1",
         "35.4",
         "52.4",
         "37.8",
         "9.8",
         "240",
         "70",
         "135",
         "7",
         "4785408",
         "2520",
         "2520"
        ],
        [
         "4",
         "5",
         "1",
         "1790",
         "1",
         "28",
         "73",
         "75",
         "17",
         "18",
         "131",
         "121",
         "85",
         "85",
         "71.0",
         "176",
         "82",
         "99",
         "16",
         "77",
         "112",
         "151",
         "98",
         "44",
         "87",
         "5.0",
         "318.24",
         "56.34",
         "233.0",
         "6700",
         "5.54",
         "17.1",
         "47.9",
         "86.5",
         "30.9",
         "35.7",
         "40.5",
         "47.7",
         "11.8",
         "129",
         "85",
         "126",
         "7",
         "4799688",
         "1680",
         "7174332"
        ],
        [
         "5",
         "6",
         "0",
         "1771",
         "0",
         "54",
         "83",
         "82",
         "18",
         "17",
         "118",
         "128",
         "89",
         "81",
         "66.0",
         "160",
         "87",
         "94",
         "16",
         "87",
         "224",
         "197",
         "149",
         "62",
         "108",
         "5.7",
         "91.29",
         "123.24",
         "177.8",
         "7400",
         "4.39",
         "13.3",
         "37.5",
         "85.4",
         "30.3",
         "35.5",
         "63.3",
         "31.4",
         "5.3",
         "358",
         "85",
         "123",
         "5",
         "7174332",
         "2391444",
         "7174332"
        ],
        [
         "6",
         "7",
         "0",
         "117",
         "1",
         "59",
         "70",
         "76",
         "17",
         "16",
         "113",
         "121",
         "70",
         "73",
         "67.0",
         "173",
         "92",
         "103",
         "22",
         "87",
         "92",
         "154",
         "183",
         "34",
         "93",
         "5.3",
         "402.9",
         "102.4",
         "223.6",
         "5300",
         "5.14",
         "16.6",
         "43.7",
         "85.0",
         "32.3",
         "38.0",
         "56.7",
         "28.3",
         "15.0",
         "239",
         "71",
         "117",
         "4",
         "4784328",
         "2391444",
         "7174332"
        ],
        [
         "7",
         "8",
         "0",
         "48",
         "0",
         "65",
         "74",
         "75",
         "25",
         "25",
         "130",
         "120",
         "85",
         "85",
         "68.8",
         "155",
         "103",
         "97",
         "15",
         "89",
         "114",
         "255",
         "247",
         "70",
         "190",
         "5.0",
         "276.42",
         "78.96",
         "212.6",
         "8000",
         "4.57",
         "14.5",
         "41.4",
         "90.6",
         "31.7",
         "35.0",
         "41.2",
         "49.0",
         "9.8",
         "301",
         "85",
         "125",
         "9",
         "4789608",
         "2391444",
         "7174332"
        ],
        [
         "8",
         "9",
         "0",
         "1166",
         "0",
         "56",
         "98",
         "96",
         "18",
         "18",
         "130",
         "120",
         "90",
         "80",
         "72.0",
         "155",
         "95",
         "112",
         "20",
         "84",
         "105",
         "181",
         "99",
         "69",
         "98",
         "6.1",
         "281.52",
         "83.4",
         "216.6",
         "5800",
         "5.06",
         "14.3",
         "40.3",
         "79.6",
         "28.3",
         "35.5",
         "51.9",
         "42.1",
         "6.0",
         "271",
         "85",
         "125",
         "6",
         "4787928",
         "1680",
         "7174332"
        ],
        [
         "9",
         "10",
         "0",
         "1667",
         "0",
         "55",
         "79",
         "81",
         "16",
         "16",
         "107",
         "113",
         "77",
         "76",
         "65.2",
         "152",
         "89",
         "104",
         "15",
         "106",
         "134",
         "219",
         "99",
         "55",
         "142",
         "6.6",
         "52.53",
         "37.38",
         "169.4",
         "6100",
         "5.99",
         "11.7",
         "36.5",
         "60.9",
         "19.5",
         "32.1",
         "48.7",
         "40.4",
         "10.9",
         "381",
         "76",
         "110",
         "8",
         "7174332",
         "480",
         "4784148"
        ],
        [
         "10",
         "11",
         "0",
         "878",
         "1",
         "64",
         "78",
         "72",
         "20",
         "20",
         "125",
         "120",
         "74",
         "72",
         "63.0",
         "157",
         "95",
         "98",
         "16",
         "95",
         "150",
         "172",
         "62",
         "60",
         "100",
         "5.9",
         "163.2",
         "188.58",
         "243.2",
         "4900",
         "5.4",
         "14.5",
         "41.8",
         "77.4",
         "26.9",
         "34.7",
         "58.5",
         "33.5",
         "8.0",
         "143",
         "73",
         "122",
         "8",
         "7174332",
         "6720",
         "7174332"
        ],
        [
         "11",
         "12",
         "0",
         "1865",
         "0",
         "83",
         "90",
         "87",
         "18",
         "16",
         "104",
         "97",
         "61",
         "65",
         "56.1",
         "152",
         "93",
         "98",
         "16",
         "83",
         "141",
         "190",
         "66",
         "53",
         "115",
         "6.24",
         "98.9",
         "21.26",
         "195.0",
         "4500",
         "4.45",
         "13.1",
         "36.4",
         "81.8",
         "29.4",
         "36.0",
         "45.9",
         "44.6",
         "9.5",
         "220",
         "63",
         "100",
         "4",
         "7174332",
         "2391444",
         "4783728"
        ],
        [
         "12",
         "13",
         "0",
         "212",
         "1",
         "80",
         "65",
         "71",
         "17",
         "17",
         "154",
         "137",
         "87",
         "79",
         "55.3",
         "159",
         "78",
         "88",
         "17",
         "125",
         "177",
         "179",
         "154",
         "40",
         "115",
         "6.5",
         "180.54",
         "56.0",
         "100.14",
         "6300",
         "5.01",
         "16.2",
         "46.7",
         "93.2",
         "32.3",
         "34.7",
         "43.8",
         "41.4",
         "14.8",
         "226",
         "83",
         "145",
         "8",
         "4796328",
         "420",
         "7174332"
        ],
        [
         "13",
         "14",
         "1",
         "335",
         "0",
         "35",
         "65",
         "64",
         "16",
         "16",
         "100",
         "100",
         "50",
         "50",
         "105.0",
         "161",
         "115",
         "123",
         "21",
         "97",
         "113",
         "199",
         "178",
         "35",
         "112",
         "5.38",
         "177.9",
         "76.8",
         "186.4",
         "4200",
         "4.66",
         "14.4",
         "39.7",
         "85.2",
         "30.9",
         "36.3",
         "63.6",
         "28.8",
         "7.6",
         "215",
         "50",
         "100",
         "7",
         "1080",
         "480",
         "4784808"
        ],
        [
         "14",
         "15",
         "1",
         "1097",
         "0",
         "38",
         "63",
         "63",
         "24",
         "23",
         "95",
         "90",
         "75",
         "75",
         "60.8",
         "159",
         "78",
         "97",
         "23",
         "91",
         "110",
         "169",
         "154",
         "35",
         "88",
         "5.5",
         "317.73",
         "129.8",
         "175.6",
         "5500",
         "4.35",
         "11.1",
         "34.5",
         "79.3",
         "25.5",
         "32.2",
         "53.8",
         "35.9",
         "10.3",
         "264",
         "75",
         "92",
         "5",
         "3840",
         "2391444",
         "4782888"
        ],
        [
         "15",
         "16",
         "0",
         "1271",
         "1",
         "75",
         "76",
         "76",
         "16",
         "16",
         "130",
         "140",
         "60",
         "60",
         "56.2",
         "162",
         "91",
         "98",
         "21",
         "91",
         "184",
         "166",
         "68",
         "55",
         "85",
         "5.4",
         "249.9",
         "46.0",
         "185.6",
         "7200",
         "5.87",
         "17.0",
         "50.1",
         "85.3",
         "29.0",
         "33.9",
         "63.1",
         "26.1",
         "10.8",
         "226",
         "60",
         "135",
         "4",
         "4783368",
         "480",
         "4783368"
        ],
        [
         "16",
         "17",
         "0",
         "839",
         "0",
         "59",
         "64",
         "60",
         "16",
         "18",
         "113",
         "116",
         "74",
         "70",
         "60.8",
         "152",
         "91",
         "99",
         "15",
         "81",
         "148",
         "183",
         "79",
         "55",
         "103",
         "5.0",
         "122.4",
         "40.2",
         "130.6",
         "7400",
         "4.51",
         "14.0",
         "38.7",
         "85.8",
         "31.0",
         "36.2",
         "51.2",
         "42.4",
         "6.4",
         "294",
         "72",
         "114",
         "5",
         "4783368",
         "2391444",
         "4783068"
        ],
        [
         "17",
         "18",
         "0",
         "453",
         "1",
         "74",
         "64",
         "65",
         "17",
         "17",
         "166",
         "157",
         "84",
         "87",
         "69.1",
         "165",
         "97",
         "98",
         "17",
         "102",
         "114",
         "190",
         "85",
         "70",
         "124",
         "4.7",
         "295.8",
         "76.1",
         "228.2",
         "6500",
         "4.37",
         "13.2",
         "38.6",
         "88.3",
         "30.2",
         "34.2",
         "30.1",
         "59.9",
         "10.0",
         "188",
         "85",
         "161",
         "8",
         "4783128",
         "5040",
         "7174332"
        ],
        [
         "18",
         "19",
         "0",
         "880",
         "0",
         "61",
         "91",
         "84",
         "17",
         "17",
         "130",
         "142",
         "97",
         "93",
         "48.4",
         "149",
         "92",
         "88",
         "15",
         "91",
         "135",
         "193",
         "127",
         "48",
         "124",
         "5.7",
         "65.28",
         "81.36",
         "185.4",
         "4900",
         "5.25",
         "14.2",
         "39.5",
         "75.2",
         "27.0",
         "35.9",
         "57.8",
         "35.4",
         "6.8",
         "182",
         "95",
         "136",
         "8",
         "4783608",
         "1920",
         "7174332"
        ],
        [
         "19",
         "20",
         "1",
         "1101",
         "1",
         "30",
         "61",
         "73",
         "25",
         "20",
         "120",
         "110",
         "70",
         "60",
         "90.6",
         "183",
         "99",
         "107",
         "22",
         "90",
         "94",
         "232",
         "226",
         "37",
         "130",
         "6.3",
         "94.8",
         "18.1",
         "44.9",
         "4700",
         "4.99",
         "14.6",
         "40.6",
         "81.4",
         "29.3",
         "36.0",
         "54.1",
         "39.0",
         "6.9",
         "200",
         "65",
         "115",
         "9",
         "480",
         "2391444",
         "2000"
        ],
        [
         "20",
         "21",
         "1",
         "985",
         "1",
         "29",
         "75",
         "75",
         "16",
         "16",
         "102",
         "106",
         "55",
         "55",
         "81.4",
         "182",
         "91",
         "102",
         "17",
         "89",
         "101",
         "149",
         "139",
         "33",
         "81",
         "5.51",
         "510.0",
         "104.2",
         "135.0",
         "6400",
         "6.01",
         "16.2",
         "46.5",
         "77.4",
         "27.0",
         "34.8",
         "48.8",
         "42.2",
         "9.0",
         "272",
         "55",
         "104",
         "6",
         "2391444",
         "2391444",
         "4784568"
        ],
        [
         "21",
         "22",
         "0",
         "716",
         "0",
         "59",
         "71",
         "75",
         "16",
         "16",
         "128",
         "119",
         "87",
         "68",
         "55.4",
         "153",
         "80",
         "100",
         "14",
         "93",
         "127",
         "244",
         "192",
         "56",
         "131",
         "4.7",
         "115.2",
         "75.8",
         "260.2",
         "5800",
         "4.72",
         "14.0",
         "39.9",
         "84.5",
         "29.7",
         "35.1",
         "50.2",
         "43.7",
         "6.1",
         "242",
         "77",
         "123",
         "6",
         "4783128",
         "120",
         "7174332"
        ],
        [
         "22",
         "23",
         "1",
         "1321",
         "0",
         "37",
         "76",
         "74",
         "16",
         "16",
         "120",
         "120",
         "80",
         "80",
         "67.2",
         "162",
         "93",
         "108",
         "19",
         "102",
         "137",
         "184",
         "132",
         "46",
         "106",
         "4.6",
         "321.3",
         "201.6",
         "166.4",
         "6300",
         "4.66",
         "14.4",
         "42.1",
         "90.3",
         "30.9",
         "34.2",
         "59.7",
         "32.5",
         "7.8",
         "238",
         "80",
         "120",
         "4",
         "7174332",
         "2391444",
         "7174332"
        ],
        [
         "23",
         "24",
         "0",
         "1625",
         "0",
         "49",
         "79",
         "73",
         "17",
         "17",
         "118",
         "106",
         "82",
         "78",
         "93.8",
         "169",
         "90",
         "120",
         "16",
         "92",
         "118",
         "256",
         "101",
         "98",
         "128",
         "5.29",
         "123.4",
         "23.74",
         "161.6",
         "4400",
         "4.8",
         "13.6",
         "42.7",
         "89.0",
         "28.3",
         "31.9",
         "61.0",
         "26.4",
         "12.6",
         "233",
         "80",
         "112",
         "6",
         "7174332",
         "720",
         "7174332"
        ],
        [
         "24",
         "25",
         "0",
         "1789",
         "0",
         "54",
         "80",
         "77",
         "17",
         "16",
         "136",
         "139",
         "83",
         "85",
         "50.9",
         "157",
         "75",
         "91",
         "14",
         "80",
         "89",
         "181",
         "90",
         "52",
         "127",
         "4.6",
         "315.69",
         "56.52",
         "234.2",
         "4500",
         "4.66",
         "14.3",
         "40.8",
         "87.6",
         "30.7",
         "35.0",
         "55.1",
         "36.8",
         "8.1",
         "119",
         "84",
         "137",
         "4",
         "7174332",
         "2391444",
         "7174332"
        ],
        [
         "25",
         "26",
         "1",
         "913",
         "0",
         "30",
         "67",
         "72",
         "17",
         "16",
         "106",
         "107",
         "70",
         "82",
         "59.2",
         "154",
         "74",
         "100",
         "15",
         "91",
         "96",
         "146",
         "76",
         "31",
         "84",
         "6.31",
         "413.1",
         "92.2",
         "169.6",
         "4900",
         "4.67",
         "13.3",
         "38.4",
         "82.2",
         "28.5",
         "34.6",
         "61.0",
         "31.5",
         "7.5",
         "234",
         "76",
         "106",
         "8",
         "480",
         "2391444",
         "4782888"
        ],
        [
         "26",
         "27",
         "0",
         "916",
         "1",
         "55",
         "70",
         "70",
         "16",
         "16",
         "115",
         "107",
         "73",
         "71",
         "75.3",
         "169",
         "94",
         "97",
         "18",
         "103",
         "116",
         "154",
         "146",
         "31",
         "82",
         "4.0",
         "375.87",
         "52.14",
         "163.4",
         "7600",
         "5.52",
         "18.2",
         "47.3",
         "85.7",
         "33.0",
         "38.5",
         "62.0",
         "26.5",
         "11.5",
         "197",
         "72",
         "111",
         "5",
         "2391764",
         "600",
         "2392404"
        ],
        [
         "27",
         "28",
         "1",
         "367",
         "0",
         "34",
         "85",
         "86",
         "17",
         "17",
         "100",
         "100",
         "70",
         "70",
         "67.6",
         "116",
         "86",
         "106",
         "19",
         "100",
         "99",
         "167",
         "78",
         "50",
         "97",
         "4.6",
         "100.98",
         "27.12",
         "50.8",
         "6500",
         "4.9",
         "14.7",
         "41.6",
         "84.9",
         "30.0",
         "35.3",
         "59.6",
         "34.6",
         "5.8",
         "263",
         "70",
         "100",
         "7",
         "4785768",
         "2391444",
         "7174332"
        ],
        [
         "28",
         "29",
         "2",
         "79",
         "0",
         "28",
         "85",
         "82",
         "26",
         "22",
         "80",
         "80",
         "60",
         "60",
         "53.1",
         "167",
         "79",
         "86",
         "19",
         "96",
         "67",
         "213",
         "74",
         "57",
         "112",
         "5.7",
         "816.0",
         "82.0",
         "172.6",
         "4200",
         "4.79",
         "14.5",
         "42.1",
         "87.9",
         "30.3",
         "34.4",
         "49.9",
         "41.9",
         "8.2",
         "231",
         "60",
         "80",
         "7",
         "4783128",
         "240",
         "4782888"
        ],
        [
         "29",
         "30",
         "1",
         "1352",
         "1",
         "42",
         "79",
         "77",
         "20",
         "21",
         "121",
         "121",
         "77",
         "83",
         "97.2",
         "178",
         "100",
         "112",
         "18",
         "100",
         "70",
         "170",
         "509",
         "27",
         "79",
         "5.4",
         "256.0",
         "56.82",
         "67.0",
         "5800",
         "4.84",
         "14.4",
         "41.3",
         "85.3",
         "29.8",
         "34.9",
         "38.0",
         "52.2",
         "9.8",
         "341",
         "80",
         "121",
         "4",
         "14400",
         "2391444",
         "2160"
        ],
        [
         "30",
         "31",
         "1",
         "756",
         "1",
         "44",
         "89",
         "87",
         "16",
         "16",
         "119",
         "117",
         "75",
         "79",
         "84.3",
         "162",
         "98",
         "111",
         "17",
         "84",
         "109",
         "163",
         "76",
         "45",
         "92",
         "4.1",
         "248.3",
         "53.2",
         "250.0",
         "4700",
         "5.28",
         "16.1",
         "46.0",
         "87.1",
         "30.5",
         "35.0",
         "40.0",
         "47.8",
         "12.2",
         "201",
         "77",
         "118",
         "7",
         "7174332",
         "2391444",
         "7174332"
        ],
        [
         "31",
         "32",
         "0",
         "1753",
         "0",
         "72",
         "78",
         "81",
         "16",
         "17",
         "143",
         "138",
         "92",
         "85",
         "53.9",
         "162",
         "75",
         "93",
         "15",
         "116",
         "92",
         "165",
         "78",
         "66",
         "93",
         "4.8",
         "153.0",
         "82.52",
         "200.8",
         "7100",
         "4.77",
         "14.9",
         "42.8",
         "89.7",
         "31.2",
         "34.8",
         "46.0",
         "44.9",
         "9.1",
         "177",
         "88",
         "140",
         "3",
         "7174332",
         "480",
         "4782968"
        ],
        [
         "32",
         "33",
         "0",
         "1210",
         "0",
         "55",
         "82",
         "86",
         "17",
         "17",
         "134",
         "121",
         "75",
         "73",
         "68.7",
         "157",
         "92",
         "105",
         "15",
         "101",
         "232",
         "227",
         "331",
         "45",
         "148",
         "6.4",
         "184.62",
         "56.4",
         "225.6",
         "5900",
         "5.29",
         "14.9",
         "42.9",
         "81.1",
         "28.2",
         "34.7",
         "59.0",
         "35.6",
         "5.4",
         "302",
         "74",
         "127",
         "4",
         "200",
         "2391444",
         "7174332"
        ],
        [
         "33",
         "34",
         "0",
         "774",
         "1",
         "58",
         "55",
         "83",
         "20",
         "19",
         "145",
         "137",
         "91",
         "91",
         "70.5",
         "161",
         "95",
         "100",
         "17",
         "99",
         "198",
         "153",
         "115",
         "50",
         "74",
         "5.0",
         "156.5",
         "28.6",
         "242.8",
         "6700",
         "5.27",
         "16.8",
         "44.3",
         "84.1",
         "31.9",
         "37.9",
         "49.6",
         "42.1",
         "8.3",
         "207",
         "91",
         "141",
         "6",
         "4787928",
         "560",
         "7174332"
        ],
        [
         "34",
         "35",
         "1",
         "543",
         "0",
         "40",
         "81",
         "82",
         "17",
         "17",
         "107",
         "119",
         "70",
         "83",
         "66.0",
         "159",
         "80",
         "106",
         "15",
         "95",
         "107",
         "153",
         "43",
         "50",
         "92",
         "5.3",
         "51.51",
         "20.2",
         "99.8",
         "7800",
         "5.68",
         "10.5",
         "34.3",
         "60.4",
         "18.5",
         "30.6",
         "47.7",
         "31.8",
         "20.5",
         "361",
         "76",
         "113",
         "8",
         "2391604",
         "480",
         "4783008"
        ],
        [
         "35",
         "36",
         "0",
         "993",
         "0",
         "58",
         "75",
         "75",
         "17",
         "18",
         "148",
         "145",
         "75",
         "74",
         "66.1",
         "154",
         "97",
         "101",
         "17",
         "117",
         "131",
         "247",
         "109",
         "58",
         "159",
         "6.42",
         "188.7",
         "70.0",
         "206.4",
         "5000",
         "4.35",
         "12.5",
         "35.4",
         "81.4",
         "28.7",
         "35.3",
         "39.8",
         "55.2",
         "5.0",
         "267",
         "74",
         "146",
         "7",
         "4784568",
         "840",
         "7174332"
        ],
        [
         "36",
         "37",
         "1",
         "1677",
         "1",
         "43",
         "69",
         "67",
         "17",
         "17",
         "106",
         "120",
         "62",
         "64",
         "84.3",
         "183",
         "82",
         "105",
         "20",
         "85",
         "92",
         "63",
         "68",
         "36",
         "91",
         "5.27",
         "60.6",
         "63.0",
         "69.6",
         "5500",
         "5.62",
         "15.8",
         "43.8",
         "77.9",
         "28.1",
         "36.1",
         "51.5",
         "35.5",
         "13.0",
         "154",
         "63",
         "113",
         "4",
         "2391444",
         "5040",
         "1680"
        ],
        [
         "37",
         "38",
         "0",
         "1494",
         "1",
         "78",
         "80",
         "79",
         "19",
         "20",
         "130",
         "131",
         "85",
         "76",
         "82.6",
         "171",
         "100",
         "112",
         "19",
         "90",
         "124",
         "146",
         "91",
         "38",
         "85",
         "5.78",
         "121.8",
         "189.68",
         "141.2",
         "4800",
         "4.82",
         "13.9",
         "40.6",
         "84.2",
         "28.8",
         "34.2",
         "52.1",
         "37.1",
         "10.8",
         "231",
         "80",
         "130",
         "3",
         "4786248",
         "960",
         "7174332"
        ],
        [
         "38",
         "39",
         "1",
         "1274",
         "1",
         "30",
         "67",
         "69",
         "17",
         "17",
         "122",
         "114",
         "79",
         "75",
         "81.6",
         "171",
         "91",
         "103",
         "18",
         "88",
         "107",
         "177",
         "186",
         "39",
         "113",
         "5.3",
         "227.46",
         "99.76",
         "294.4",
         "7800",
         "5.74",
         "18.6",
         "50.6",
         "88.2",
         "32.4",
         "36.8",
         "56.9",
         "33.8",
         "9.3",
         "250",
         "77",
         "118",
         "6",
         "4783848",
         "2391444",
         "7174332"
        ],
        [
         "39",
         "40",
         "0",
         "1856",
         "1",
         "73",
         "78",
         "99",
         "20",
         "99",
         "110",
         "99",
         "80",
         "99",
         "73.1",
         "173",
         "91",
         "102",
         "18",
         "88",
         "92",
         "242",
         "94",
         "56",
         "154",
         "6.8",
         "180.5",
         "89.0",
         "201.6",
         "5700",
         "5.12",
         "14.8",
         "41.9",
         "81.8",
         "28.9",
         "35.3",
         "47.0",
         "42.6",
         "10.4",
         "198",
         "89",
         "104",
         "6",
         "7174332",
         "420",
         "7174332"
        ],
        [
         "40",
         "41",
         "0",
         "1421",
         "1",
         "49",
         "61",
         "60",
         "20",
         "20",
         "120",
         "126",
         "86",
         "88",
         "73.9",
         "172",
         "95",
         "103",
         "18",
         "88",
         "90",
         "182",
         "138",
         "39",
         "129",
         "4.1",
         "191.25",
         "70.84",
         "219.8",
         "6700",
         "5.08",
         "17.0",
         "46.1",
         "90.7",
         "33.5",
         "36.9",
         "44.7",
         "40.0",
         "15.3",
         "181",
         "87",
         "123",
         "5",
         "2391524",
         "2391444",
         "7174332"
        ],
        [
         "41",
         "42",
         "1",
         "440",
         "1",
         "27",
         "92",
         "95",
         "17",
         "17",
         "140",
         "135",
         "68",
         "72",
         "73.1",
         "167",
         "77",
         "96",
         "17",
         "81",
         "96",
         "189",
         "78",
         "36",
         "112",
         "4.28",
         "274.8",
         "74.2",
         "154.2",
         "5800",
         "5.64",
         "18.6",
         "50.7",
         "89.9",
         "33.0",
         "36.7",
         "48.7",
         "42.4",
         "8.9",
         "252",
         "70",
         "137",
         "2",
         "2391444",
         "1680",
         "6160"
        ],
        [
         "42",
         "43",
         "0",
         "1156",
         "1",
         "68",
         "88",
         "85",
         "18",
         "18",
         "139",
         "135",
         "73",
         "70",
         "62.1",
         "156",
         "82",
         "99",
         "16",
         "89",
         "70",
         "187",
         "67",
         "63",
         "105",
         "5.8",
         "180.54",
         "59.64",
         "202.6",
         "3500",
         "4.74",
         "16.4",
         "45.0",
         "94.9",
         "34.6",
         "36.4",
         "55.9",
         "38.1",
         "6.0",
         "141",
         "71",
         "137",
         "5",
         "7174332",
         "3360",
         "4784568"
        ],
        [
         "43",
         "44",
         "0",
         "693",
         "1",
         "69",
         "72",
         "72",
         "16",
         "16",
         "172",
         "171",
         "116",
         "116",
         "65.6",
         "168",
         "85",
         "96",
         "17",
         "83",
         "116",
         "194",
         "109",
         "48",
         "107",
         "4.4",
         "255.5",
         "45.2",
         "228.4",
         "5800",
         "4.61",
         "14.9",
         "42.0",
         "91.1",
         "32.3",
         "35.5",
         "50.0",
         "31.7",
         "18.3",
         "198",
         "116",
         "171",
         "3",
         "18480",
         "720",
         "7174332"
        ],
        [
         "44",
         "45",
         "1",
         "326",
         "0",
         "36",
         "80",
         "80",
         "17",
         "17",
         "110",
         "110",
         "80",
         "80",
         "72.0",
         "167",
         "97",
         "115",
         "21",
         "96",
         "103",
         "190",
         "139",
         "42",
         "103",
         "5.7",
         "91.8",
         "88.8",
         "260.0",
         "6400",
         "4.91",
         "15.0",
         "41.4",
         "84.3",
         "30.5",
         "36.2",
         "58.1",
         "29.3",
         "12.6",
         "196",
         "80",
         "110",
         "7",
         "4783848",
         "240",
         "480"
        ],
        [
         "45",
         "46",
         "0",
         "1151",
         "0",
         "75",
         "84",
         "80",
         "17",
         "17",
         "140",
         "140",
         "90",
         "85",
         "54.0",
         "149",
         "89",
         "98",
         "20",
         "84",
         "139",
         "183",
         "150",
         "61",
         "104",
         "5.6",
         "45.9",
         "15.52",
         "202.6",
         "4400",
         "5.39",
         "14.7",
         "42.0",
         "77.9",
         "27.3",
         "35.0",
         "48.2",
         "43.5",
         "8.3",
         "247",
         "87",
         "140",
         "3",
         "7174332",
         "2391444",
         "7174332"
        ],
        [
         "46",
         "47",
         "0",
         "1197",
         "1",
         "49",
         "94",
         "95",
         "16",
         "16",
         "130",
         "130",
         "90",
         "90",
         "102.1",
         "185",
         "113",
         "117",
         "24",
         "110",
         "116",
         "228",
         "386",
         "44",
         "130",
         "5.3",
         "197.88",
         "64.8",
         "144.6",
         "7800",
         "6.1",
         "17.3",
         "48.4",
         "79.3",
         "28.4",
         "35.7",
         "41.1",
         "47.1",
         "11.8",
         "338",
         "90",
         "130",
         "7",
         "7174332",
         "1440",
         "7174332"
        ],
        [
         "47",
         "48",
         "1",
         "780",
         "0",
         "36",
         "90",
         "102",
         "16",
         "17",
         "94",
         "94",
         "71",
         "71",
         "68.1",
         "168",
         "77",
         "105",
         "14",
         "92",
         "95",
         "145",
         "66",
         "58",
         "65",
         "4.1",
         "236.13",
         "134.96",
         "221.8",
         "6800",
         "4.64",
         "13.9",
         "39.9",
         "86.0",
         "30.0",
         "34.8",
         "59.8",
         "31.3",
         "8.9",
         "304",
         "71",
         "94",
         "5",
         "732",
         "244",
         "732"
        ],
        [
         "48",
         "49",
         "0",
         "1838",
         "1",
         "51",
         "66",
         "72",
         "18",
         "18",
         "88",
         "99",
         "61",
         "64",
         "91.9",
         "177",
         "104",
         "112",
         "19",
         "89",
         "94",
         "162",
         "107",
         "45",
         "92",
         "5.66",
         "151.98",
         "45.14",
         "238.8",
         "5800",
         "5.35",
         "16.4",
         "46.4",
         "86.7",
         "30.7",
         "35.3",
         "47.2",
         "39.2",
         "13.6",
         "164",
         "62",
         "93",
         "6",
         "7174332",
         "2391444",
         "7174332"
        ],
        [
         "49",
         "50",
         "0",
         "920",
         "0",
         "63",
         "75",
         "72",
         "24",
         "24",
         "110",
         "110",
         "80",
         "80",
         "50.2",
         "158",
         "71",
         "91",
         "15",
         "82",
         "123",
         "215",
         "80",
         "52",
         "132",
         "5.1",
         "168.3",
         "74.4",
         "236.8",
         "4200",
         "4.77",
         "12.2",
         "38.3",
         "80.3",
         "25.6",
         "31.9",
         "61.0",
         "30.7",
         "8.3",
         "208",
         "80",
         "110",
         "4",
         "4789608",
         "2391444",
         "7174332"
        ]
       ],
       "shape": {
        "columns": 45,
        "rows": 1891
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>Gen.code</th>\n",
       "      <th>ID</th>\n",
       "      <th>Dm2</th>\n",
       "      <th>Dm4</th>\n",
       "      <th>E11</th>\n",
       "      <th>E12</th>\n",
       "      <th>E21</th>\n",
       "      <th>E22</th>\n",
       "      <th>E31</th>\n",
       "      <th>...</th>\n",
       "      <th>Neutrophils</th>\n",
       "      <th>Lymphocyte</th>\n",
       "      <th>Mixed</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>DBP</th>\n",
       "      <th>SBP</th>\n",
       "      <th>gdi</th>\n",
       "      <th>work_activity</th>\n",
       "      <th>transport</th>\n",
       "      <th>lesiretime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>35.8</td>\n",
       "      <td>52.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>249</td>\n",
       "      <td>67</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>34560</td>\n",
       "      <td>2391444</td>\n",
       "      <td>1440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>743</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>65</td>\n",
       "      <td>62</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>52.5</td>\n",
       "      <td>36.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>226</td>\n",
       "      <td>76</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>7174332</td>\n",
       "      <td>360</td>\n",
       "      <td>7174332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>58.8</td>\n",
       "      <td>32.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>288</td>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4783608</td>\n",
       "      <td>480</td>\n",
       "      <td>7174332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>140</td>\n",
       "      <td>...</td>\n",
       "      <td>52.4</td>\n",
       "      <td>37.8</td>\n",
       "      <td>9.8</td>\n",
       "      <td>240</td>\n",
       "      <td>70</td>\n",
       "      <td>135</td>\n",
       "      <td>7</td>\n",
       "      <td>4785408</td>\n",
       "      <td>2520</td>\n",
       "      <td>2520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>131</td>\n",
       "      <td>...</td>\n",
       "      <td>40.5</td>\n",
       "      <td>47.7</td>\n",
       "      <td>11.8</td>\n",
       "      <td>129</td>\n",
       "      <td>85</td>\n",
       "      <td>126</td>\n",
       "      <td>7</td>\n",
       "      <td>4799688</td>\n",
       "      <td>1680</td>\n",
       "      <td>7174332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>1887</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>81</td>\n",
       "      <td>86</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>51.1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>247</td>\n",
       "      <td>74</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>4796328</td>\n",
       "      <td>840</td>\n",
       "      <td>4783608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>1888</td>\n",
       "      <td>0</td>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>127</td>\n",
       "      <td>...</td>\n",
       "      <td>52.3</td>\n",
       "      <td>39.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>197</td>\n",
       "      <td>74</td>\n",
       "      <td>121</td>\n",
       "      <td>5</td>\n",
       "      <td>7174332</td>\n",
       "      <td>840</td>\n",
       "      <td>7174332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>1889</td>\n",
       "      <td>2</td>\n",
       "      <td>317</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>57.9</td>\n",
       "      <td>34.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>223</td>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>960</td>\n",
       "      <td>240</td>\n",
       "      <td>4782888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>1890</td>\n",
       "      <td>0</td>\n",
       "      <td>1331</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>84</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>54.4</td>\n",
       "      <td>32.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>229</td>\n",
       "      <td>80</td>\n",
       "      <td>125</td>\n",
       "      <td>6</td>\n",
       "      <td>4783608</td>\n",
       "      <td>1680</td>\n",
       "      <td>17280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>1891</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>54</td>\n",
       "      <td>76</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>36.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>199</td>\n",
       "      <td>59</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>4783248</td>\n",
       "      <td>360</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1891 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         n  Gen.code    ID  Dm2  Dm4  E11  E12  E21  E22  E31  ...  \\\n",
       "0        1         1  1090    1   36   80   75   30   20  130  ...   \n",
       "1        2         0   743    0   59   65   62   16   16  132  ...   \n",
       "2        3         0   242    0   58   83   85   17   17  120  ...   \n",
       "3        4         1    33    0   61   69   70   29   29  140  ...   \n",
       "4        5         1  1790    1   28   73   75   17   18  131  ...   \n",
       "...    ...       ...   ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1886  1887         0   219    1   62   81   86   18   18  109  ...   \n",
       "1887  1888         0   499    0   58   81   78   17   18  127  ...   \n",
       "1888  1889         2   317    0   30   87   87   17   18  100  ...   \n",
       "1889  1890         0  1331    1   56   84   80   16   16  130  ...   \n",
       "1890  1891         2   166    1   19   54   76   17   17  107  ...   \n",
       "\n",
       "      Neutrophils  Lymphocyte  Mixed  Platelets  DBP  SBP  gdi  work_activity  \\\n",
       "0            35.8        52.6   11.6        249   67  120    6          34560   \n",
       "1            52.5        36.4   11.1        226   76  128    5        7174332   \n",
       "2            58.8        32.1    9.1        288   70  120    5        4783608   \n",
       "3            52.4        37.8    9.8        240   70  135    7        4785408   \n",
       "4            40.5        47.7   11.8        129   85  126    7        4799688   \n",
       "...           ...         ...    ...        ...  ...  ...  ...            ...   \n",
       "1886         51.1        37.0   11.9        247   74  109    3        4796328   \n",
       "1887         52.3        39.7    8.0        197   74  121    5        7174332   \n",
       "1888         57.9        34.9    7.2        223   60  100    5            960   \n",
       "1889         54.4        32.8   12.8        229   80  125    6        4783608   \n",
       "1890         36.8        50.0   13.2        199   59   99    6        4783248   \n",
       "\n",
       "      transport  lesiretime  \n",
       "0       2391444        1440  \n",
       "1           360     7174332  \n",
       "2           480     7174332  \n",
       "3          2520        2520  \n",
       "4          1680     7174332  \n",
       "...         ...         ...  \n",
       "1886        840     4783608  \n",
       "1887        840     7174332  \n",
       "1888        240     4782888  \n",
       "1889       1680       17280  \n",
       "1890        360         960  \n",
       "\n",
       "[1891 rows x 45 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-15 14:07:37,661] A new study created in memory with name: no-name-4b4570ca-8dde-44c1-8284-36f7b9ac25b2\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\missforest\\missforest.py:333: UserWarning: Label encoding is no longer performed by default. Users will have to perform categorical features encoding by themselves.\n",
      "  warnings.warn(\"Label encoding is no longer performed by default. \"\n",
      "100%|██████████| 3/3 [00:32<00:00, 10.84s/it]\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\missforest\\missforest.py:490: UserWarning: Label encoding is no longer performed by default. Users will have to perform categorical features encoding by themselves.\n",
      "  warnings.warn(\"Label encoding is no longer performed by default. \"\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\missforest\\missforest.py:494: UserWarning: In version 4.2.3, estimator fitting process is moved to `fit` method. `MissForest` will now imputes unseen missing values with fitted estimators with `transform` method. To retain the old behaviour, use `fit_transform` to fit the whole unseen data instead.\n",
      "  warnings.warn(f\"In version {VERSION}, estimator fitting process \"\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.46it/s]\n",
      "[I 2025-04-15 14:08:11,777] Trial 0 finished with value: 114107.11227269446 and parameters: {'iters': 3, 'scale': False}. Best is trial 0 with value: 114107.11227269446.\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\missforest\\missforest.py:333: UserWarning: Label encoding is no longer performed by default. Users will have to perform categorical features encoding by themselves.\n",
      "  warnings.warn(\"Label encoding is no longer performed by default. \"\n",
      "100%|██████████| 12/12 [02:28<00:00, 12.41s/it]\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\missforest\\missforest.py:490: UserWarning: Label encoding is no longer performed by default. Users will have to perform categorical features encoding by themselves.\n",
      "  warnings.warn(\"Label encoding is no longer performed by default. \"\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\missforest\\missforest.py:494: UserWarning: In version 4.2.3, estimator fitting process is moved to `fit` method. `MissForest` will now imputes unseen missing values with fitted estimators with `transform` method. To retain the old behaviour, use `fit_transform` to fit the whole unseen data instead.\n",
      "  warnings.warn(f\"In version {VERSION}, estimator fitting process \"\n",
      "100%|██████████| 12/12 [00:05<00:00,  2.06it/s]\n",
      "[I 2025-04-15 14:10:47,191] Trial 1 finished with value: 111581.23221126181 and parameters: {'iters': 12, 'scale': True}. Best is trial 1 with value: 111581.23221126181.\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\missforest\\missforest.py:333: UserWarning: Label encoding is no longer performed by default. Users will have to perform categorical features encoding by themselves.\n",
      "  warnings.warn(\"Label encoding is no longer performed by default. \"\n",
      "100%|██████████| 11/11 [02:14<00:00, 12.26s/it]\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\missforest\\missforest.py:490: UserWarning: Label encoding is no longer performed by default. Users will have to perform categorical features encoding by themselves.\n",
      "  warnings.warn(\"Label encoding is no longer performed by default. \"\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\missforest\\missforest.py:494: UserWarning: In version 4.2.3, estimator fitting process is moved to `fit` method. `MissForest` will now imputes unseen missing values with fitted estimators with `transform` method. To retain the old behaviour, use `fit_transform` to fit the whole unseen data instead.\n",
      "  warnings.warn(f\"In version {VERSION}, estimator fitting process \"\n",
      "100%|██████████| 11/11 [00:04<00:00,  2.34it/s]\n",
      "[I 2025-04-15 14:13:07,417] Trial 2 finished with value: 111626.51788094059 and parameters: {'iters': 11, 'scale': True}. Best is trial 1 with value: 111581.23221126181.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization completed!\n",
      "Best Trial Hyperparameters:\n",
      "  iters: 12\n",
      "  scale: True\n",
      "Best Objective Value (aggregated error): 111581.23221126181\n"
     ]
    }
   ],
   "source": [
    "best_method, best_val = optimize_imputation_hyperparams(imputation_func=do_mf,original_df=new_df,missing_percent=30, timelimit=300,\n",
    "                                                        continuous_cols=continuous_cols, discrete_cols=discrete_cols, categorical_cols=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_missingness(df, show_missingness=False, random_state=42):\n",
    "    \"\"\"\n",
    "    Simulate missingness by dropping rows with missing values and reintroducing them.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        show_missingness (bool): If True, prints missingness percentages.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Original DataFrame without missing values, simulated DataFrame with missingness, and a mask.\n",
    "    \"\"\"\n",
    "    missing_original = df.isna().mean()\n",
    "    df2 = df.dropna().reset_index(drop=True)\n",
    "    df3 = df2.copy()\n",
    "    missing_mask = pd.DataFrame(False, index=df3.index, columns=df3.columns)\n",
    "\n",
    "    for col in df3.columns:\n",
    "        n_missing = int(round(missing_original[col] * len(df3)))\n",
    "        if n_missing > 0:\n",
    "            missing_indices = df3.sample(n=n_missing, random_state=random_state).index\n",
    "            df3.loc[missing_indices, col] = np.nan\n",
    "            missing_mask.loc[missing_indices, col] = True\n",
    "\n",
    "    if show_missingness:\n",
    "        missing_df3 = df3.isna().mean()\n",
    "        print(\"Missingness Comparison:\")\n",
    "        for col in df.columns:\n",
    "            print(f\"Column '{col}': Original: {missing_original[col]*100:.2f}% \\t -> \\t df3: {missing_df3[col]*100:.2f}%\")\n",
    "\n",
    "    return df2, df3, missing_mask\n",
    "\n",
    "def create_missings(df: pd.DataFrame, missingness: float, random_seed: float = 96):\n",
    "    \"\"\"\n",
    "    Create random missingness in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        missingness (float): Percentage of missing values to introduce.\n",
    "        random_seed (float): Seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (original DataFrame, DataFrame with missing values, mask DataFrame)\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    mask = np.random.rand(*df.shape) < (missingness / 100)\n",
    "    mask_df = pd.DataFrame(mask, columns=df.columns)\n",
    "    df_missing = df.mask(mask)\n",
    "    return df, df_missing, mask_df\n",
    "\n",
    "\n",
    "def select_best_imputations(imputed_dfs, original_df, mask_df, continuous_cols, discrete_cols, categorical_cols, method_info=None, method_names=None):\n",
    "    \"\"\"\n",
    "    Evaluate one or several imputed DataFrames and determine an aggregated error.\n",
    "\n",
    "    For each column with simulated missing data (per mask_df), numeric columns\n",
    "    are scored using Mean Absolute Error (MAE) while categorical columns are scored\n",
    "    by misclassification rate (1 - accuracy). An overall aggregated error is returned,\n",
    "    which is the mean error over all evaluated columns.\n",
    "\n",
    "    Parameters:\n",
    "      imputed_dfs (list of pd.DataFrame): A list of imputed DataFrames.\n",
    "      original_df (pd.DataFrame): The original (complete) DataFrame.\n",
    "      mask_df (pd.DataFrame): Boolean DataFrame with True at positions where values are masked.\n",
    "      continuous_cols (list): List of continuous numeric column names.\n",
    "      discrete_cols (list): List of discrete numeric column names.\n",
    "      categorical_cols (list): List of categorical column names.\n",
    "      method_info (str, optional): Text description of the method and its hyperparameters.\n",
    "      method_names (list, optional): List of names for each imputation method candidate.\n",
    "\n",
    "    Returns:\n",
    "      best_imputed_df (pd.DataFrame): A DataFrame where, for each column with missing values,\n",
    "                                     the candidate with the lowest error is chosen.\n",
    "      summary_table (pd.DataFrame): A summary table with metrics for each column.\n",
    "      aggregated_error (float): The average error across columns (lower is better).\n",
    "    \"\"\"\n",
    "    n_methods = len(imputed_dfs)\n",
    "    \n",
    "    if method_info is not None:\n",
    "        parts = method_info.split(',')\n",
    "        base_name = parts[0].strip()\n",
    "        params = ','.join(parts[1:]).strip() if len(parts) > 1 else \"\"\n",
    "        method_names = [f\"{base_name} ({params})\"] * n_methods\n",
    "    elif method_names is None:\n",
    "        method_names = [f\"Method {i+1}\" for i in range(n_methods)]\n",
    "    \n",
    "    summary_list = []\n",
    "    best_method_per_col = {}\n",
    "\n",
    "    for col in original_df.columns:\n",
    "        if col in continuous_cols:\n",
    "            col_type = \"Continuous\"\n",
    "        elif col in discrete_cols:\n",
    "            col_type = \"Discrete\"\n",
    "        elif col in categorical_cols:\n",
    "            col_type = \"Categorical\"\n",
    "        else:\n",
    "            col_type = str(original_df[col].dtype)\n",
    "\n",
    "        if mask_df[col].sum() == 0:\n",
    "            best_method_per_col[col] = None\n",
    "            summary_list.append({\n",
    "                'Column': col,\n",
    "                'Data Type': col_type,\n",
    "                'Best Method': None,\n",
    "                'Metric': np.nan,  \n",
    "            })\n",
    "            continue\n",
    "\n",
    "        col_errors = []\n",
    "        for df_imp in imputed_dfs:\n",
    "            if col_type in [\"Continuous\", \"Discrete\"]:\n",
    "                try:\n",
    "                    imp_vals = pd.to_numeric(df_imp[col][mask_df[col]], errors='coerce')\n",
    "                    orig_vals = pd.to_numeric(original_df[col][mask_df[col]], errors='coerce')\n",
    "                except Exception as e:\n",
    "                    imp_vals = df_imp[col][mask_df[col]]\n",
    "                    orig_vals = original_df[col][mask_df[col]]\n",
    "                errors = np.abs(imp_vals - orig_vals)\n",
    "                mae = errors.mean()\n",
    "                col_errors.append(mae)\n",
    "            else:\n",
    "                correct = (df_imp[col][mask_df[col]] == original_df[col][mask_df[col]])\n",
    "                accuracy = correct.mean()\n",
    "                col_errors.append(1 - accuracy)\n",
    "\n",
    "        if col_type in [\"Continuous\", \"Discrete\"]:\n",
    "            best_idx = int(np.nanargmin(col_errors))\n",
    "        else:\n",
    "            best_idx = int(np.nanargmin(col_errors))\n",
    "        best_method = method_names[best_idx]\n",
    "        best_metric = col_errors[best_idx]\n",
    "\n",
    "        best_method_per_col[col] = best_idx\n",
    "        summary_list.append({\n",
    "            'Column': col,\n",
    "            'Data Type': col_type,\n",
    "            'Best Method': best_method,\n",
    "            'Metric': best_metric,\n",
    "        })\n",
    "\n",
    "    summary_table = pd.DataFrame(summary_list)\n",
    "    \n",
    "    best_imputed_df = original_df.copy()\n",
    "    for cat in categorical_cols:\n",
    "        if cat in best_imputed_df:\n",
    "            best_imputed_df[cat] = best_imputed_df[cat].astype(object)\n",
    "\n",
    "    for col in original_df.columns:\n",
    "        if mask_df[col].sum() > 0 and best_method_per_col[col] is not None:\n",
    "            method_idx = best_method_per_col[col]\n",
    "            best_imputed_df.loc[mask_df[col], col] = \\\n",
    "                imputed_dfs[method_idx].loc[mask_df[col], col]\n",
    "\n",
    "    errors = summary_table['Metric'].dropna().values\n",
    "    aggregated_error = np.mean(errors) if len(errors) > 0 else np.nan\n",
    "\n",
    "    return best_imputed_df, summary_table, aggregated_error\n",
    "\n",
    "\n",
    "def optimize_imputation_hyperparams(imputation_func, \n",
    "                                    original_df, \n",
    "                                    df_missing, \n",
    "                                    mask_df, \n",
    "                                    continuous_cols, \n",
    "                                    discrete_cols, \n",
    "                                    categorical_cols, \n",
    "                                    timelimit=600,    # in seconds\n",
    "                                    min_trials=20,\n",
    "                                    random_seed=96):\n",
    "    \"\"\"\n",
    "    Optimize hyperparameters for an imputation function using Optuna.\n",
    "\n",
    "    This function takes the complete (original) DataFrame and a missing percentage.\n",
    "    It uses `create_missings` to generate a DataFrame with simulated missing values and\n",
    "    a corresponding mask. Then it runs the candidate imputation method on the incomplete\n",
    "    DataFrame, evaluates the imputed results against the original DataFrame using the mask,\n",
    "    and guides the hyperparameter search based on an aggregated error (lower is better).\n",
    "\n",
    "    Parameters:\n",
    "        imputation_func (callable): An imputation function (do_knn, do_mice, do_mf, or do_midas).\n",
    "        original_df (pd.DataFrame): The complete ground-truth DataFrame.\n",
    "        missing_percent (float): Percentage of missing values to simulate.\n",
    "        continuous_cols (list): List of continuous numeric column names.\n",
    "        discrete_cols (list): List of discrete numeric column names.\n",
    "        categorical_cols (list): List of categorical column names.\n",
    "        timelimit (int): Maximum time in seconds to run the optimization.\n",
    "        min_trials (int): Minimum number of Optuna trials to run.\n",
    "        random_seed (int): Seed for generating missingness (passed to create_missings).\n",
    "\n",
    "    Returns:\n",
    "        best_trial: The best trial object from the study.\n",
    "        best_value: The best (lowest) aggregated objective value.\n",
    "    \"\"\"\n",
    "    # Generate missing values and mask using the provided function.\n",
    "    # _, df_missing, mask_df = create_missings(original_df, missingness=missing_percent, random_seed=random_seed)\n",
    "\n",
    "    def objective(trial):\n",
    "        func_name = imputation_func.__name__\n",
    "        params = {}\n",
    "\n",
    "        if func_name == \"do_knn\":\n",
    "            params['n_neighbors'] = trial.suggest_int(\"n_neighbors\", 3, 15)\n",
    "            params['scale'] = trial.suggest_categorical(\"scale\", [True, False])\n",
    "            # Run imputation on df_missing, not the original complete data.\n",
    "            imputed_df = imputation_func(df_missing, \n",
    "                                         continuous_cols=continuous_cols, \n",
    "                                         discrete_cols=discrete_cols, \n",
    "                                         categorical_cols=categorical_cols, \n",
    "                                         **params)\n",
    "            imputed_dfs = [imputed_df]\n",
    "            method_info = f\"KNN, n_neighbors={params['n_neighbors']}, scale={params['scale']}\"\n",
    "        elif func_name == \"do_mice\":\n",
    "            params['iters'] = trial.suggest_int(\"iters\", 5, 20)\n",
    "            params['strat'] = trial.suggest_categorical(\"strat\", ['normal', 'shap', 'fast'])\n",
    "            params['scale'] = trial.suggest_categorical(\"scale\", [True, False])\n",
    "            imputed_df = imputation_func(df_missing,\n",
    "                                         continuous_cols=continuous_cols, \n",
    "                                         discrete_cols=discrete_cols, \n",
    "                                         categorical_cols=categorical_cols,\n",
    "                                         **params)\n",
    "            imputed_dfs = [imputed_df]\n",
    "            method_info = f\"MICE, iters={params['iters']}, strat={params['strat']}, scale={params['scale']}\"\n",
    "        elif func_name == \"do_mf\":\n",
    "            params['iters'] = trial.suggest_int(\"iters\", 3, 15)\n",
    "            params['scale'] = trial.suggest_categorical(\"scale\", [True, False])\n",
    "            imputed_df = imputation_func(df_missing,\n",
    "                                         continuous_cols=continuous_cols, \n",
    "                                         discrete_cols=discrete_cols, \n",
    "                                         categorical_cols=categorical_cols,\n",
    "                                         **params)\n",
    "            imputed_dfs = [imputed_df]\n",
    "            method_info = f\"MissForest, iters={params['iters']}, scale={params['scale']}\"\n",
    "        elif func_name == \"do_midas\":\n",
    "            params['layer'] = trial.suggest_categorical(\"layer\", [[256,256], [128,128], [512,256]])\n",
    "            params['vae'] = trial.suggest_categorical(\"vae\", [True, False])\n",
    "            params['samples'] = trial.suggest_int(\"samples\", 5, 20)\n",
    "            imputed_dfs, method_info = imputation_func(df_missing,\n",
    "                                                       continuous_cols=continuous_cols, \n",
    "                                                       discrete_cols=discrete_cols, \n",
    "                                                       categorical_cols=categorical_cols,\n",
    "                                                       **params)\n",
    "            imputed_dfs = [imputed_dfs[0]]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported imputation function: {func_name}\")\n",
    "\n",
    "        # Evaluate the imputed result by comparing against the original complete DataFrame.\n",
    "        _, _, aggregated_error = select_best_imputations(\n",
    "            imputed_dfs, original_df, mask_df, continuous_cols, discrete_cols, categorical_cols,\n",
    "            method_info=method_info\n",
    "        )\n",
    "\n",
    "        if np.isnan(aggregated_error):\n",
    "            aggregated_error = 1e6\n",
    "\n",
    "        return aggregated_error\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, timeout=timelimit, n_trials=min_trials)\n",
    "\n",
    "    best_trial = study.best_trial\n",
    "    best_value = best_trial.value\n",
    "\n",
    "    print(\"Optimization completed!\")\n",
    "    print(\"Best Trial Hyperparameters:\")\n",
    "    for key, value in best_trial.params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(f\"Best Objective Value (aggregated error): {best_value}\")\n",
    "\n",
    "    return best_trial, best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_midas(df,\n",
    "             continuous_cols=None,\n",
    "             discrete_cols=None,\n",
    "             categorical_cols=None,\n",
    "             layer: list = [256, 256],\n",
    "             vae: bool = True,\n",
    "             samples: int = 10,\n",
    "             random_seed: float = 96):\n",
    "    \"\"\"\n",
    "    Imputes missing values using the MIDAS model.\n",
    "\n",
    "    Parameters:\n",
    "      df (pd.DataFrame): Input dataframe with NaNs in both numeric & categorical.\n",
    "      continuous_cols (list): List of continuous column names.\n",
    "      discrete_cols (list): List of discrete (numeric but not continuous) column names.\n",
    "      categorical_cols (list): List of categorical column names.\n",
    "\n",
    "    Returns:\n",
    "      imps (list): A list of imputed dataframes, with original dtypes restored.\n",
    "      method_info (str): Summary of MIDAS params used.\n",
    "    \"\"\"\n",
    "    # 1. One‑hot encode the categoricals\n",
    "    md_cat_data, md_cats = md.cat_conv(df[categorical_cols])\n",
    "\n",
    "    # 2. Build the “wide” DF: drop raw cats, append one‑hots\n",
    "    df_num = df.drop(columns=categorical_cols)\n",
    "    data_in = pd.concat([df_num, md_cat_data], axis=1)\n",
    "\n",
    "    # 3. Record & re‑insert the NaN locations so MIDAS sees them as missing\n",
    "    na_mask = data_in.isnull()\n",
    "    data_in[na_mask] = np.nan\n",
    "\n",
    "    # 4. Scale only the numeric columns in place\n",
    "    num_cols = discrete_cols + continuous_cols\n",
    "    scaler = MinMaxScaler()\n",
    "    data_in[num_cols] = scaler.fit_transform(data_in[num_cols])\n",
    "\n",
    "    # 5. Build & train the MIDAS model\n",
    "    imputer = md.Midas(\n",
    "        layer_structure=layer,\n",
    "        vae_layer=vae,\n",
    "        seed=random_seed,\n",
    "        input_drop=0.75\n",
    "    )\n",
    "    imputer.build_model(data_in, softmax_columns=md_cats)\n",
    "    imputer.train_model(training_epochs=20)\n",
    "\n",
    "    # 6. Generate multiple imputations\n",
    "    raw_imps = imputer.generate_samples(m=samples).output_list\n",
    "\n",
    "    # 7. Decode each imputed DF back to original structure\n",
    "    flat_cats = [c for grp in md_cats for c in grp]\n",
    "    imps = []\n",
    "\n",
    "    for imp_df in raw_imps:\n",
    "        # 7a. inverse‑scale numeric cols\n",
    "        imp_df[num_cols] = scaler.inverse_transform(imp_df[num_cols])\n",
    "\n",
    "        # 7b. decode one‑hots (before dropping them!)\n",
    "        decoded = {}\n",
    "        for i, grp in enumerate(md_cats):\n",
    "            # just in case, only keep those actually present\n",
    "            present = [c for c in grp if c in imp_df.columns]\n",
    "            # idxmax → gives the dummy column name with highest prob\n",
    "            decoded[categorical_cols[i]] = imp_df[present].idxmax(axis=1)\n",
    "\n",
    "        cat_df = pd.DataFrame(decoded, index=imp_df.index)\n",
    "\n",
    "        # 7c. now drop the dummy cols\n",
    "        base = imp_df.drop(columns=flat_cats, errors='ignore')\n",
    "\n",
    "        # 7d. concat in your decoded cat columns\n",
    "        merged = pd.concat([base, cat_df], axis=1)\n",
    "\n",
    "        # 7e. round discrete cols\n",
    "        merged[discrete_cols] = merged[discrete_cols].round().astype(int)\n",
    "\n",
    "        imps.append(merged)\n",
    "\n",
    "    method_info = f\"MIDAS, params: samples={samples}, layer={layer}, vae={vae}\"\n",
    "    return imps, method_info\n",
    "\n",
    "\n",
    "def run_full_pipeline(df: pd.DataFrame, \n",
    "                      simulate:bool=False,               # True for simulated missingness, False for random missingness\n",
    "                      missingness_value: float = 10.0,   # used only for random missingness (percent)\n",
    "                      show_missingness: bool = False,\n",
    "                      timelimit: int = 600, \n",
    "                      min_trials: int = 20, \n",
    "                      random_seed: int = 96):\n",
    "    \"\"\"\n",
    "    Run the full pipeline to find the best hyperparameters for each imputation method.\n",
    "\n",
    "    The pipeline performs these steps:\n",
    "    \n",
    "      1. Preprocesses the DataFrame using `prep`, which cleans the data,\n",
    "         encodes categorical variables, and splits features into continuous,\n",
    "         discrete, and categorical lists.\n",
    "      2. Introduces missingness using either simulated missingness (reintroducing missingness \n",
    "         based on the original NaN proportions) or random missingness (dropping values randomly\n",
    "         given a specified missing percentage).\n",
    "      3. Runs hyperparameter optimization (via `optimize_imputation_hyperparams`) for each candidate \n",
    "         imputation method (e.g., do_knn, do_mice, do_mf, do_midas).\n",
    "         \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        missing_type (str): \"simulate\" to simulate missingness using original missing proportions,\n",
    "                            \"random\" to drop values randomly.\n",
    "        missingness_value (float): Percentage of missingness (only used if missing_type == \"random\").\n",
    "        show_missingness (bool): If True, prints missingness comparison when using simulate missingness.\n",
    "        timelimit (int): Time limit (in seconds) for each hyperparameter optimization study.\n",
    "        min_trials (int): Minimum number of trials for each study.\n",
    "        random_seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are method names (strings) and the values are the best \n",
    "              hyperparameter dictionaries (from the best Optuna trial) for that method.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Preprocess Data\n",
    "    continuous_cols, discrete_cols, categorical_cols, df_clean, encoders = prep(df)\n",
    "    \n",
    "    # Step 2: Create Missingness\n",
    "    # Note: For simulation, the missing proportions are taken from the original df.\n",
    "    if simulate: \n",
    "        # simulate_missingness returns: (complete_df, df_with_missing, missing_mask)\n",
    "        original_complete, df_missing, mask_df = simulate_missingness(df, \n",
    "                                                                      show_missingness=show_missingness,\n",
    "                                                                      random_state=random_seed)\n",
    "    else:   \n",
    "        original_complete, df_missing, mask_df = create_missings(df_clean, \n",
    "                                                                 missingness=missingness_value, \n",
    "                                                                 random_seed=random_seed)\n",
    "        \n",
    "    # The original_complete DataFrame is assumed to be ground truth for evaluation.\n",
    "    # If missing_type==\"simulate\", original_complete is the complete-case subset from the original data.\n",
    "    # For random, the df_clean (preprocessed and complete) is used and missingness is artificially introduced.\n",
    "\n",
    "    # Step 3: Define candidate imputation methods to optimize.\n",
    "    # It is assumed that these functions are defined: do_knn, do_mice, do_mf, do_midas.\n",
    "    candidate_methods = {\n",
    "        \"KNN\": do_knn,\n",
    "        \"MICE\": do_mice,\n",
    "        \"MissForest\": do_mf,\n",
    "        \"MIDAS\": do_midas\n",
    "    }\n",
    "    \n",
    "    best_hyperparams = {}\n",
    "    \n",
    "    # Optimize hyperparameters for each imputation method candidate.\n",
    "    for method_name, imputation_func in candidate_methods.items():\n",
    "        print(f\"\\nOptimizing hyperparameters for {method_name}...\")\n",
    "        try:\n",
    "            best_trial, best_value = optimize_imputation_hyperparams(\n",
    "                imputation_func=imputation_func,\n",
    "                original_df=original_complete,\n",
    "                df_missing=df_missing,\n",
    "                mask_df=mask_df,\n",
    "                continuous_cols=continuous_cols,\n",
    "                discrete_cols=discrete_cols,\n",
    "                categorical_cols=categorical_cols,\n",
    "                timelimit=timelimit,\n",
    "                min_trials=min_trials,\n",
    "                random_seed=random_seed\n",
    "            )\n",
    "            best_hyperparams[method_name] = best_trial.params\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while optimizing {method_name}: {e}\")\n",
    "            best_hyperparams[method_name] = None\n",
    "    \n",
    "    return best_hyperparams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-17 01:49:48,645] A new study created in memory with name: no-name-fd3a6ac4-36a8-4e26-b961-5db36ce10509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing hyperparameters for KNN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-17 01:49:49,551] Trial 0 finished with value: 118879.16867876558 and parameters: {'n_neighbors': 14, 'scale': True}. Best is trial 0 with value: 118879.16867876558.\n",
      "[I 2025-04-17 01:49:50,359] Trial 1 finished with value: 119277.57665411044 and parameters: {'n_neighbors': 12, 'scale': True}. Best is trial 0 with value: 118879.16867876558.\n",
      "[I 2025-04-17 01:49:51,152] Trial 2 finished with value: 120520.94788333244 and parameters: {'n_neighbors': 4, 'scale': True}. Best is trial 0 with value: 118879.16867876558.\n",
      "[I 2025-04-17 01:49:52,028] Trial 3 finished with value: 119163.2803176755 and parameters: {'n_neighbors': 10, 'scale': True}. Best is trial 0 with value: 118879.16867876558.\n",
      "[I 2025-04-17 01:49:52,828] Trial 4 finished with value: 118637.68422901373 and parameters: {'n_neighbors': 15, 'scale': True}. Best is trial 4 with value: 118637.68422901373.\n",
      "[I 2025-04-17 01:49:53,634] Trial 5 finished with value: 131986.46211469793 and parameters: {'n_neighbors': 13, 'scale': False}. Best is trial 4 with value: 118637.68422901373.\n",
      "[I 2025-04-17 01:49:54,428] Trial 6 finished with value: 132225.77485844144 and parameters: {'n_neighbors': 12, 'scale': False}. Best is trial 4 with value: 118637.68422901373.\n",
      "[I 2025-04-17 01:49:55,209] Trial 7 finished with value: 133164.48857084982 and parameters: {'n_neighbors': 8, 'scale': False}. Best is trial 4 with value: 118637.68422901373.\n",
      "[I 2025-04-17 01:49:56,002] Trial 8 finished with value: 131144.97101252343 and parameters: {'n_neighbors': 6, 'scale': False}. Best is trial 4 with value: 118637.68422901373.\n",
      "[I 2025-04-17 01:49:56,617] Trial 9 finished with value: 131749.72717920842 and parameters: {'n_neighbors': 3, 'scale': False}. Best is trial 4 with value: 118637.68422901373.\n",
      "[I 2025-04-17 01:49:57,445] Trial 10 finished with value: 118637.68422901373 and parameters: {'n_neighbors': 15, 'scale': True}. Best is trial 4 with value: 118637.68422901373.\n",
      "[I 2025-04-17 01:49:58,262] Trial 11 finished with value: 118637.68422901373 and parameters: {'n_neighbors': 15, 'scale': True}. Best is trial 4 with value: 118637.68422901373.\n",
      "[I 2025-04-17 01:49:59,076] Trial 12 finished with value: 118637.68422901373 and parameters: {'n_neighbors': 15, 'scale': True}. Best is trial 4 with value: 118637.68422901373.\n",
      "[I 2025-04-17 01:49:59,869] Trial 13 finished with value: 119163.2803176755 and parameters: {'n_neighbors': 10, 'scale': True}. Best is trial 4 with value: 118637.68422901373.\n",
      "[I 2025-04-17 01:50:00,668] Trial 14 finished with value: 119277.57665411044 and parameters: {'n_neighbors': 12, 'scale': True}. Best is trial 4 with value: 118637.68422901373.\n",
      "[I 2025-04-17 01:50:01,451] Trial 15 finished with value: 119248.31901091494 and parameters: {'n_neighbors': 8, 'scale': True}. Best is trial 4 with value: 118637.68422901373.\n",
      "[I 2025-04-17 01:50:02,254] Trial 16 finished with value: 118637.68422901373 and parameters: {'n_neighbors': 15, 'scale': True}. Best is trial 4 with value: 118637.68422901373.\n",
      "[I 2025-04-17 01:50:03,045] Trial 17 finished with value: 119785.09835174638 and parameters: {'n_neighbors': 13, 'scale': True}. Best is trial 4 with value: 118637.68422901373.\n",
      "[I 2025-04-17 01:50:03,833] Trial 18 finished with value: 119163.2803176755 and parameters: {'n_neighbors': 10, 'scale': True}. Best is trial 4 with value: 118637.68422901373.\n",
      "[I 2025-04-17 01:50:04,644] Trial 19 finished with value: 119785.09835174638 and parameters: {'n_neighbors': 13, 'scale': True}. Best is trial 4 with value: 118637.68422901373.\n",
      "[I 2025-04-17 01:50:04,646] A new study created in memory with name: no-name-14923f47-b8c8-407e-8014-984c9c45f0b7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization completed!\n",
      "Best Trial Hyperparameters:\n",
      "  n_neighbors: 15\n",
      "  scale: True\n",
      "Best Objective Value (aggregated error): 118637.68422901373\n",
      "\n",
      "Optimizing hyperparameters for MICE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\miceforest\\imputation_kernel.py:831: RuntimeWarning: overflow encountered in cast\n",
      "  bachelor_preds = bachelor_preds.astype(_PRE_LINK_DATATYPE)\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\miceforest\\imputation_kernel.py:776: RuntimeWarning: overflow encountered in cast\n",
      "  candidate_preds = candidate_preds.astype(_PRE_LINK_DATATYPE)  # type: ignore\n",
      "[W 2025-04-17 01:50:16,150] Trial 0 failed with parameters: {'iters': 13, 'strat': 'shap', 'scale': True} because of the following error: ValueError('data must be finite, check for nan or inf values').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Matin\\AppData\\Local\\Temp\\ipykernel_8740\\3942454051.py\", line 216, in objective\n",
      "    imputed_df = imputation_func(df_missing,\n",
      "  File \"C:\\Users\\Matin\\AppData\\Local\\Temp\\ipykernel_8740\\746599116.py\", line 31, in do_mice\n",
      "    kernel.mice(iterations=iters, verbose=False)  # Disable verbose output\n",
      "  File \"c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\miceforest\\imputation_kernel.py\", line 1186, in mice\n",
      "    imputation_values = self._mean_match_mice(\n",
      "  File \"c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\miceforest\\imputation_kernel.py\", line 971, in _mean_match_mice\n",
      "    imputation_values = self._mean_match_nearest_neighbors(\n",
      "  File \"c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\miceforest\\imputation_kernel.py\", line 602, in _mean_match_nearest_neighbors\n",
      "    kd_tree = KDTree(candidate_preds, leafsize=16, balanced_tree=False)\n",
      "  File \"c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\spatial\\_kdtree.py\", line 360, in __init__\n",
      "    super().__init__(data, leafsize, compact_nodes, copy_data,\n",
      "  File \"_ckdtree.pyx\", line 561, in scipy.spatial._ckdtree.cKDTree.__init__\n",
      "ValueError: data must be finite, check for nan or inf values\n",
      "[W 2025-04-17 01:50:16,152] Trial 0 failed with value None.\n",
      "[I 2025-04-17 01:50:16,154] A new study created in memory with name: no-name-252407aa-58b4-42bc-a887-0848a10fd815\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\missforest\\missforest.py:333: UserWarning: Label encoding is no longer performed by default. Users will have to perform categorical features encoding by themselves.\n",
      "  warnings.warn(\"Label encoding is no longer performed by default. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while optimizing MICE: data must be finite, check for nan or inf values\n",
      "\n",
      "Optimizing hyperparameters for MissForest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:50<00:00, 11.06s/it]\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\missforest\\missforest.py:490: UserWarning: Label encoding is no longer performed by default. Users will have to perform categorical features encoding by themselves.\n",
      "  warnings.warn(\"Label encoding is no longer performed by default. \"\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\missforest\\missforest.py:494: UserWarning: In version 4.2.3, estimator fitting process is moved to `fit` method. `MissForest` will now imputes unseen missing values with fitted estimators with `transform` method. To retain the old behaviour, use `fit_transform` to fit the whole unseen data instead.\n",
      "  warnings.warn(f\"In version {VERSION}, estimator fitting process \"\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.76it/s]\n",
      "[I 2025-04-17 01:52:11,137] Trial 0 finished with value: 115055.00721726334 and parameters: {'iters': 10, 'scale': True}. Best is trial 0 with value: 115055.00721726334.\n",
      "[I 2025-04-17 01:52:11,139] A new study created in memory with name: no-name-563287aa-6762-4cf4-8c8c-900e9008f337\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [256, 256] which is of type list.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [128, 128] which is of type list.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [512, 256] which is of type list.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization completed!\n",
      "Best Trial Hyperparameters:\n",
      "  iters: 10\n",
      "  scale: True\n",
      "Best Objective Value (aggregated error): 115055.00721726334\n",
      "\n",
      "Optimizing hyperparameters for MIDAS...\n",
      "Size index: [41, 2]\n",
      "\n",
      "Computation graph constructed\n",
      "\n",
      "Model initialised\n",
      "\n",
      "Epoch: 0 , loss: 15.93519032203545\n",
      "Epoch: 1 , loss: 9.922870611740372\n",
      "Epoch: 2 , loss: 8.405207900677697\n",
      "Epoch: 3 , loss: 7.580558227280439\n",
      "Epoch: 4 , loss: 7.005114943294202\n",
      "Epoch: 5 , loss: 6.631417302762047\n",
      "Epoch: 6 , loss: 6.278475389642231\n",
      "Epoch: 7 , loss: 6.117289745201499\n",
      "Epoch: 8 , loss: 5.962418370327707\n",
      "Epoch: 9 , loss: 5.876365071636135\n",
      "Epoch: 10 , loss: 5.787296319411973\n",
      "Epoch: 11 , loss: 5.700790550749181\n",
      "Epoch: 12 , loss: 5.653845500137846\n",
      "Epoch: 13 , loss: 5.618617571006387\n",
      "Epoch: 14 , loss: 5.613604367789575\n",
      "Epoch: 15 , loss: 5.611704951625759\n",
      "Epoch: 16 , loss: 5.554807873095497\n",
      "Epoch: 17 , loss: 5.5319306365514205\n",
      "Epoch: 18 , loss: 5.515414286467989\n",
      "Epoch: 19 , loss: 5.493824595111912\n",
      "Training complete. Saving file...\n",
      "Model saved in file: tmp/MIDAS\n",
      "INFO:tensorflow:Restoring parameters from tmp/MIDAS\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-17 01:52:55,098] Trial 0 finished with value: 137592.03328454602 and parameters: {'layer': [256, 256], 'vae': True, 'samples': 13}. Best is trial 0 with value: 137592.03328454602.\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [256, 256] which is of type list.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [128, 128] which is of type list.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Matin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [512, 256] which is of type list.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size index: [41, 2]\n",
      "\n",
      "Computation graph constructed\n",
      "\n",
      "Model initialised\n",
      "\n",
      "Epoch: 0 , loss: 14.557120808100295\n",
      "Epoch: 1 , loss: 9.09260251562474\n",
      "Epoch: 2 , loss: 7.8573198520531085\n",
      "Epoch: 3 , loss: 7.113313852730444\n",
      "Epoch: 4 , loss: 6.603931871511168\n",
      "Epoch: 5 , loss: 6.285801665257599\n",
      "Epoch: 6 , loss: 6.068915443905329\n",
      "Epoch: 7 , loss: 5.876272076267307\n",
      "Epoch: 8 , loss: 5.788735308889615\n",
      "Epoch: 9 , loss: 5.729687084585933\n",
      "Epoch: 10 , loss: 5.6512592970314675\n",
      "Epoch: 11 , loss: 5.5855839696981135\n",
      "Epoch: 12 , loss: 5.560512122461351\n",
      "Epoch: 13 , loss: 5.528206421157061\n",
      "Epoch: 14 , loss: 5.519819425324262\n",
      "Epoch: 15 , loss: 5.5105722475860075\n",
      "Epoch: 16 , loss: 5.473051515676207\n",
      "Epoch: 17 , loss: 5.4573142851813365\n",
      "Epoch: 18 , loss: 5.444874674586926\n",
      "Epoch: 19 , loss: 5.424031071743722\n",
      "Training complete. Saving file...\n",
      "Model saved in file: tmp/MIDAS\n",
      "INFO:tensorflow:Restoring parameters from tmp/MIDAS\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-17 01:53:54,803] Trial 1 finished with value: 132424.4626437458 and parameters: {'layer': [512, 256], 'vae': True, 'samples': 13}. Best is trial 1 with value: 132424.4626437458.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization completed!\n",
      "Best Trial Hyperparameters:\n",
      "  layer: [512, 256]\n",
      "  vae: True\n",
      "  samples: 13\n",
      "Best Objective Value (aggregated error): 132424.4626437458\n"
     ]
    }
   ],
   "source": [
    "best_params = run_full_pipeline(new_df,timelimit=60,random_seed=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN': {'n_neighbors': 6, 'scale': True},\n",
       " 'MICE': {'iters': 6, 'strat': 'normal', 'scale': False},\n",
       " 'MissForest': {'iters': 6, 'scale': False},\n",
       " 'MIDAS': {'layer': [128, 128], 'vae': True, 'samples': 19}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E23',\n",
       " 'Hb.A1C',\n",
       " 'CreatininUrine',\n",
       " 'PotassiumUrineRandom',\n",
       " 'SodiumUrineRandom',\n",
       " 'R.B.C',\n",
       " 'Hemoglobin',\n",
       " 'Hematocrit',\n",
       " 'MCV',\n",
       " 'MCH',\n",
       " 'MCHC',\n",
       " 'Neutrophils',\n",
       " 'Lymphocyte',\n",
       " 'Mixed']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dm2']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dm4',\n",
       " 'E11',\n",
       " 'E12',\n",
       " 'E21',\n",
       " 'E22',\n",
       " 'E31',\n",
       " 'E32',\n",
       " 'E41',\n",
       " 'E42',\n",
       " 'E24',\n",
       " 'E25',\n",
       " 'E26',\n",
       " 'E27',\n",
       " 'FastingBloodSugar',\n",
       " 'Glucose2hpp',\n",
       " 'Cholestrol',\n",
       " 'Triglycerides',\n",
       " 'HDL',\n",
       " 'LDL',\n",
       " 'W.B.C',\n",
       " 'Platelets',\n",
       " 'DBP',\n",
       " 'SBP',\n",
       " 'gdi',\n",
       " 'work_activity',\n",
       " 'transport',\n",
       " 'lesiretime']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
